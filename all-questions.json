[
  {
    "id": "q001",
    "category": "라이브러리 임포트",
    "question": "NumPy 라이브러리를 임포트할 때 관례적으로 사용하는 별칭은?",
    "options": [
      "np",
      "numpy"
    ],
    "correctAnswer": 0,
    "explanation": "NumPy는 관례적으로 'np'로 임포트합니다. 이는 전 세계적으로 통용되는 표준입니다.",
    "code": "import numpy as np",
    "difficulty": "easy"
  },
  {
    "id": "q002",
    "category": "라이브러리 임포트",
    "question": "Pandas 라이브러리를 임포트할 때 관례적으로 사용하는 별칭은?",
    "options": [
      "pandas",
      "pd"
    ],
    "correctAnswer": 1,
    "explanation": "Pandas는 관례적으로 'pd'로 임포트합니다. 이는 데이터 분석에서 가장 널리 사용되는 별칭입니다.",
    "code": "import pandas as pd",
    "difficulty": "easy"
  },
  {
    "id": "q003",
    "category": "라이브러리 임포트",
    "question": "Matplotlib의 pyplot 모듈을 임포트할 때 관례적으로 사용하는 별칭은?",
    "options": [
      "pyplot",
      "plt"
    ],
    "correctAnswer": 1,
    "explanation": "Matplotlib.pyplot은 관례적으로 'plt'로 임포트합니다. 이는 시각화 작업에서 표준으로 사용됩니다.",
    "code": "import matplotlib.pyplot as plt",
    "difficulty": "easy"
  },
  {
    "id": "q004",
    "category": "라이브러리 임포트",
    "question": "Seaborn 라이브러리를 임포트할 때 관례적으로 사용하는 별칭은?",
    "options": [
      "seaborn",
      "sns"
    ],
    "correctAnswer": 1,
    "explanation": "Seaborn은 관례적으로 'sns'로 임포트합니다. 이는 통계적 시각화에서 널리 사용되는 별칭입니다.",
    "code": "import seaborn as sns",
    "difficulty": "easy"
  },
  {
    "id": "q005",
    "category": "라이브러리 임포트",
    "question": "scikit-learn에서 train_test_split을 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn.model_selection import train_test_split",
      "from sklearn import train_test_split"
    ],
    "correctAnswer": 0,
    "explanation": "train_test_split은 sklearn.model_selection 모듈에 있습니다. 하위 모듈에서 직접 임포트해야 합니다.",
    "code": "from sklearn.model_selection import train_test_split",
    "difficulty": "medium"
  },
  {
    "id": "q006",
    "category": "라이브러리 임포트",
    "question": "TensorFlow를 임포트할 때 관례적으로 사용하는 별칭은?",
    "options": [
      "tf",
      "tensorflow"
    ],
    "correctAnswer": 0,
    "explanation": "TensorFlow는 관례적으로 'tf'로 임포트합니다. 이는 딥러닝 분야에서 표준으로 사용됩니다.",
    "code": "import tensorflow as tf",
    "difficulty": "easy"
  },
  {
    "id": "q007",
    "category": "라이브러리 임포트",
    "question": "XGBoost의 분류기를 임포트하는 올바른 방법은?",
    "options": [
      "from xgboost import XGBClassifier",
      "import xgboost as XGBClassifier"
    ],
    "correctAnswer": 0,
    "explanation": "XGBClassifier는 xgboost 패키지에서 직접 임포트해야 합니다. 별칭을 사용하지 않고 클래스명을 직접 임포트합니다.",
    "code": "from xgboost import XGBClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q008",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 StandardScaler를 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn import StandardScaler",
      "from sklearn.preprocessing import StandardScaler"
    ],
    "correctAnswer": 1,
    "explanation": "StandardScaler는 sklearn.preprocessing 모듈에 있습니다. 전처리 관련 기능은 preprocessing 하위 모듈에 위치합니다.",
    "code": "from sklearn.preprocessing import StandardScaler",
    "difficulty": "medium"
  },
  {
    "id": "q009",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 accuracy_score를 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn import accuracy_score",
      "from sklearn.metrics import accuracy_score"
    ],
    "correctAnswer": 1,
    "explanation": "accuracy_score는 sklearn.metrics 모듈에 있습니다. 성능 평가 관련 함수들은 metrics 하위 모듈에 위치합니다.",
    "code": "from sklearn.metrics import accuracy_score",
    "difficulty": "medium"
  },
  {
    "id": "q010",
    "category": "라이브러리 임포트",
    "question": "TensorFlow에서 Keras를 임포트하는 올바른 방법은?",
    "options": [
      "import keras",
      "from tensorflow import keras"
    ],
    "correctAnswer": 1,
    "explanation": "TensorFlow 2.x부터는 Keras가 TensorFlow에 통합되었습니다. 'from tensorflow import keras'가 올바른 방법입니다.",
    "code": "from tensorflow import keras",
    "difficulty": "medium"
  },
  {
    "id": "q011",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 RandomForestClassifier를 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn import RandomForestClassifier",
      "from sklearn.ensemble import RandomForestClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "RandomForestClassifier는 sklearn.ensemble 모듈에 있습니다. 앙상블 모델들은 ensemble 하위 모듈에 위치합니다.",
    "code": "from sklearn.ensemble import RandomForestClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q012",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 LogisticRegression을 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn.linear_model import LogisticRegression",
      "from sklearn import LogisticRegression"
    ],
    "correctAnswer": 0,
    "explanation": "LogisticRegression은 sklearn.linear_model 모듈에 있습니다. 선형 모델들은 linear_model 하위 모듈에 위치합니다.",
    "code": "from sklearn.linear_model import LogisticRegression",
    "difficulty": "medium"
  },
  {
    "id": "q013",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 KNeighborsClassifier를 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn import KNeighborsClassifier",
      "from sklearn.neighbors import KNeighborsClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "KNeighborsClassifier는 sklearn.neighbors 모듈에 있습니다. 거리 기반 알고리즘들은 neighbors 하위 모듈에 위치합니다.",
    "code": "from sklearn.neighbors import KNeighborsClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q014",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 DecisionTreeClassifier를 임포트하는 올바른 방법은?",
    "options": [
      "from sklearn import DecisionTreeClassifier",
      "from sklearn.tree import DecisionTreeClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "DecisionTreeClassifier는 sklearn.tree 모듈에 있습니다. 트리 기반 알고리즘들은 tree 하위 모듈에 위치합니다.",
    "code": "from sklearn.tree import DecisionTreeClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q015",
    "category": "라이브러리 임포트",
    "question": "한글 폰트를 설정할 때 사용하는 matplotlib 명령어는?",
    "options": [
      "plt.rc('font', family='NanumGothicCoding')",
      "plt.font('NanumGothicCoding')"
    ],
    "correctAnswer": 0,
    "explanation": "matplotlib에서 한글 폰트를 설정할 때는 rc() 함수를 사용합니다. 'font' 키와 'family' 값을 지정해야 합니다.",
    "code": "plt.rc('font', family='NanumGothicCoding')",
    "difficulty": "hard"
  },
  {
    "id": "q016",
    "category": "데이터 불러오기",
    "question": "CSV 파일을 읽을 때 한글 인코딩 문제가 발생하면 시도해야 할 인코딩은?",
    "options": [
      "cp949",
      "utf-16"
    ],
    "correctAnswer": 0,
    "explanation": "한글 데이터는 주로 cp949 인코딩을 사용합니다. utf-8이 실패하면 cp949를 시도하는 것이 일반적입니다.",
    "code": "df = pd.read_csv('file.csv', encoding='cp949')",
    "difficulty": "medium"
  },
  {
    "id": "q017",
    "category": "데이터 불러오기",
    "question": "Excel 파일을 읽을 때 필요한 엔진은?",
    "options": [
      "xlrd",
      "openpyxl"
    ],
    "correctAnswer": 1,
    "explanation": "xlsx 파일을 읽을 때는 openpyxl 엔진이 필요합니다. xlrd는 구형 xls 파일용입니다.",
    "code": "df = pd.read_excel('file.xlsx', engine='openpyxl')",
    "difficulty": "medium"
  },
  {
    "id": "q018",
    "category": "데이터 불러오기",
    "question": "데이터의 크기를 확인하는 pandas 메서드는?",
    "options": [
      "df.shape",
      "df.size"
    ],
    "correctAnswer": 0,
    "explanation": "df.shape는 (행수, 열수) 튜플을 반환합니다. df.size는 전체 요소 개수만 반환합니다.",
    "code": "print(df.shape)",
    "difficulty": "easy"
  },
  {
    "id": "q019",
    "category": "데이터 불러오기",
    "question": "데이터의 첫 5행을 보여주는 pandas 메서드는?",
    "options": [
      "df.head()",
      "df.top()"
    ],
    "correctAnswer": 0,
    "explanation": "df.head()는 기본적으로 첫 5행을 보여줍니다. df.top()은 존재하지 않는 메서드입니다.",
    "code": "print(df.head())",
    "difficulty": "easy"
  },
  {
    "id": "q020",
    "category": "데이터 불러오기",
    "question": "데이터의 정보(타입, 결측치 등)를 확인하는 pandas 메서드는?",
    "options": [
      "df.describe()",
      "df.info()"
    ],
    "correctAnswer": 1,
    "explanation": "df.info()는 데이터 타입, 결측치 개수, 메모리 사용량 등을 보여줍니다. df.describe()는 통계 요약입니다.",
    "code": "print(df.info())",
    "difficulty": "easy"
  },
  {
    "id": "q021",
    "category": "데이터 불러오기",
    "question": "결측치를 확인하는 pandas 메서드는?",
    "options": [
      "df.isnull().sum()",
      "df.missing().sum()"
    ],
    "correctAnswer": 0,
    "explanation": "df.isnull() 또는 df.isna()로 결측치를 확인할 수 있습니다. df.missing()은 존재하지 않는 메서드입니다.",
    "code": "print(df.isnull().sum())",
    "difficulty": "easy"
  },
  {
    "id": "q022",
    "category": "데이터 불러오기",
    "question": "기술통계를 확인하는 pandas 메서드는?",
    "options": [
      "df.describe()",
      "df.stats()"
    ],
    "correctAnswer": 0,
    "explanation": "df.describe()는 평균, 표준편차, 최솟값, 최댓값 등 기술통계를 보여줍니다. df.stats()는 존재하지 않는 메서드입니다.",
    "code": "print(df.describe())",
    "difficulty": "easy"
  },
  {
    "id": "q023",
    "category": "데이터 불러오기",
    "question": "대용량 파일을 분할해서 읽을 때 사용하는 파라미터는?",
    "options": [
      "batch_size",
      "chunksize"
    ],
    "correctAnswer": 1,
    "explanation": "chunksize 파라미터를 사용하면 파일을 청크 단위로 나누어 읽을 수 있습니다. 메모리 효율적입니다.",
    "code": "for chunk in pd.read_csv('large.csv', chunksize=1000):",
    "difficulty": "hard"
  },
  {
    "id": "q024",
    "category": "데이터 불러오기",
    "question": "특정 컬럼만 읽을 때 사용하는 파라미터는?",
    "options": [
      "columns",
      "usecols"
    ],
    "correctAnswer": 1,
    "explanation": "usecols 파라미터로 읽을 컬럼을 지정할 수 있습니다. 메모리 사용량을 줄일 수 있습니다.",
    "code": "df = pd.read_csv('file.csv', usecols=['col1', 'col2'])",
    "difficulty": "medium"
  },
  {
    "id": "q025",
    "category": "데이터 불러오기",
    "question": "날짜 컬럼을 자동으로 파싱할 때 사용하는 파라미터는?",
    "options": [
      "parse_dates",
      "date_parser"
    ],
    "correctAnswer": 0,
    "explanation": "parse_dates 파라미터로 날짜 컬럼을 지정하면 자동으로 datetime 타입으로 변환됩니다.",
    "code": "df = pd.read_csv('file.csv', parse_dates=['date_col'])",
    "difficulty": "medium"
  },
  {
    "id": "q026",
    "category": "데이터 불러오기",
    "question": "Excel 파일에서 특정 시트를 읽을 때 사용하는 파라미터는?",
    "options": [
      "sheet",
      "sheet_name"
    ],
    "correctAnswer": 1,
    "explanation": "sheet_name 파라미터로 읽을 시트를 지정할 수 있습니다. 시트 번호나 이름을 사용할 수 있습니다.",
    "code": "df = pd.read_excel('file.xlsx', sheet_name=0)",
    "difficulty": "medium"
  },
  {
    "id": "q027",
    "category": "데이터 불러오기",
    "question": "데이터 타입을 강제로 지정할 때 사용하는 파라미터는?",
    "options": [
      "type",
      "dtype"
    ],
    "correctAnswer": 1,
    "explanation": "dtype 파라미터로 컬럼별 데이터 타입을 딕셔너리 형태로 지정할 수 있습니다.",
    "code": "df = pd.read_csv('file.csv', dtype={'col1': str, 'col2': int})",
    "difficulty": "medium"
  },
  {
    "id": "q028",
    "category": "데이터 불러오기",
    "question": "구분자가 탭인 파일을 읽을 때 사용하는 파라미터는?",
    "options": [
      "delimiter='\\t'",
      "sep='\\t'"
    ],
    "correctAnswer": 1,
    "explanation": "sep 파라미터로 구분자를 지정할 수 있습니다. 탭은 '\\t'로 표현합니다.",
    "code": "df = pd.read_csv('file.tsv', sep='\\t')",
    "difficulty": "medium"
  },
  {
    "id": "q029",
    "category": "데이터 불러오기",
    "question": "첫 번째 행을 헤더로 사용하지 않을 때 사용하는 파라미터는?",
    "options": [
      "header=None",
      "no_header=True"
    ],
    "correctAnswer": 0,
    "explanation": "header=None으로 설정하면 첫 번째 행도 데이터로 읽습니다. 자동으로 컬럼명이 숫자로 지정됩니다.",
    "code": "df = pd.read_csv('file.csv', header=None)",
    "difficulty": "medium"
  },
  {
    "id": "q030",
    "category": "데이터 불러오기",
    "question": "현재 작업 디렉토리를 확인하는 방법은?",
    "options": [
      "os.getcwd()",
      "os.pwd()"
    ],
    "correctAnswer": 0,
    "explanation": "os.getcwd()는 현재 작업 디렉토리를 반환합니다. os.pwd()는 존재하지 않는 함수입니다.",
    "code": "import os\nprint(os.getcwd())",
    "difficulty": "easy"
  },
  {
    "id": "q031",
    "category": "데이터 시각화",
    "question": "범주형 데이터의 분포를 확인할 때 사용하는 seaborn 함수는?",
    "options": [
      "sns.countplot()",
      "sns.barplot()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.countplot()은 범주형 데이터의 빈도를 막대그래프로 보여줍니다. sns.barplot()은 수치형 데이터의 평균을 보여줍니다.",
    "code": "sns.countplot(data=df, x='category')",
    "difficulty": "easy"
  },
  {
    "id": "q032",
    "category": "데이터 시각화",
    "question": "수치형 데이터의 분포를 히스토그램으로 보여주는 seaborn 함수는?",
    "options": [
      "sns.histplot()",
      "sns.distplot()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.histplot()은 수치형 데이터의 분포를 히스토그램으로 보여줍니다. sns.distplot()은 deprecated되었습니다.",
    "code": "sns.histplot(data=df, x='value', bins=30)",
    "difficulty": "easy"
  },
  {
    "id": "q033",
    "category": "데이터 시각화",
    "question": "두 변수 간의 관계를 산점도로 보여주는 seaborn 함수는?",
    "options": [
      "sns.scatterplot()",
      "sns.pointplot()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.scatterplot()은 두 변수 간의 관계를 산점도로 보여줍니다. sns.pointplot()은 범주형 데이터의 평균을 보여줍니다.",
    "code": "sns.scatterplot(data=df, x='x_var', y='y_var')",
    "difficulty": "easy"
  },
  {
    "id": "q034",
    "category": "데이터 시각화",
    "question": "상관관계를 히트맵으로 보여주는 seaborn 함수는?",
    "options": [
      "sns.heatmap()",
      "sns.heat()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.heatmap()은 상관관계나 다른 2차원 데이터를 히트맵으로 시각화합니다. sns.heat()는 존재하지 않는 함수입니다.",
    "code": "sns.heatmap(corr_matrix, annot=True)",
    "difficulty": "easy"
  },
  {
    "id": "q035",
    "category": "데이터 시각화",
    "question": "그래프를 출력하기 위해 반드시 호출해야 하는 matplotlib 함수는?",
    "options": [
      "plt.display()",
      "plt.show()"
    ],
    "correctAnswer": 1,
    "explanation": "plt.show()는 그래프를 화면에 출력하는 함수입니다. plt.display()는 존재하지 않는 함수입니다.",
    "code": "plt.show()",
    "difficulty": "easy"
  },
  {
    "id": "q036",
    "category": "데이터 시각화",
    "question": "그래프의 제목을 설정하는 matplotlib 함수는?",
    "options": [
      "plt.title()",
      "plt.label()"
    ],
    "correctAnswer": 0,
    "explanation": "plt.title()은 그래프의 제목을 설정합니다. plt.label()은 축 라벨을 설정하는 함수입니다.",
    "code": "plt.title('Graph Title')",
    "difficulty": "easy"
  },
  {
    "id": "q037",
    "category": "데이터 시각화",
    "question": "그래프의 크기를 설정하는 matplotlib 함수는?",
    "options": [
      "plt.figure(figsize=(width, height))",
      "plt.size(width, height)"
    ],
    "correctAnswer": 0,
    "explanation": "plt.figure(figsize=(width, height))로 그래프의 크기를 설정할 수 있습니다. plt.size()는 존재하지 않는 함수입니다.",
    "code": "plt.figure(figsize=(10, 6))",
    "difficulty": "medium"
  },
  {
    "id": "q038",
    "category": "데이터 시각화",
    "question": "범례를 추가하는 matplotlib 함수는?",
    "options": [
      "plt.legend()",
      "plt.legendary()"
    ],
    "correctAnswer": 0,
    "explanation": "plt.legend()는 그래프에 범례를 추가합니다. plt.legendary()는 존재하지 않는 함수입니다.",
    "code": "plt.legend()",
    "difficulty": "easy"
  },
  {
    "id": "q039",
    "category": "데이터 시각화",
    "question": "그래프를 파일로 저장하는 matplotlib 함수는?",
    "options": [
      "plt.savefig()",
      "plt.save()"
    ],
    "correctAnswer": 0,
    "explanation": "plt.savefig()은 그래프를 파일로 저장합니다. plt.save()는 존재하지 않는 함수입니다.",
    "code": "plt.savefig('plot.png')",
    "difficulty": "easy"
  },
  {
    "id": "q040",
    "category": "데이터 시각화",
    "question": "seaborn의 테마를 설정하는 함수는?",
    "options": [
      "sns.set_theme()",
      "sns.set_style()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.set_theme()은 seaborn의 전체적인 테마를 설정합니다. sns.set_style()은 스타일만 설정합니다.",
    "code": "sns.set_theme(style='whitegrid')",
    "difficulty": "medium"
  },
  {
    "id": "q041",
    "category": "데이터 시각화",
    "question": "박스플롯을 그리는 seaborn 함수는?",
    "options": [
      "sns.boxplot()",
      "sns.box()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.boxplot()은 박스플롯을 그리는 함수입니다. sns.box()는 존재하지 않는 함수입니다.",
    "code": "sns.boxplot(data=df, x='category', y='value')",
    "difficulty": "easy"
  },
  {
    "id": "q042",
    "category": "데이터 시각화",
    "question": "바이올린플롯을 그리는 seaborn 함수는?",
    "options": [
      "sns.violin()",
      "sns.violinplot()"
    ],
    "correctAnswer": 1,
    "explanation": "sns.violinplot()은 바이올린플롯을 그리는 함수입니다. sns.violin()은 존재하지 않는 함수입니다.",
    "code": "sns.violinplot(data=df, x='category', y='value')",
    "difficulty": "medium"
  },
  {
    "id": "q043",
    "category": "데이터 시각화",
    "question": "조인트플롯을 그리는 seaborn 함수는?",
    "options": [
      "sns.joint()",
      "sns.jointplot()"
    ],
    "correctAnswer": 1,
    "explanation": "sns.jointplot()은 두 변수의 관계를 조인트플롯으로 보여주는 함수입니다. sns.joint()는 존재하지 않는 함수입니다.",
    "code": "sns.jointplot(data=df, x='x_var', y='y_var')",
    "difficulty": "medium"
  },
  {
    "id": "q044",
    "category": "데이터 시각화",
    "question": "상관관계를 계산하는 pandas 메서드는?",
    "options": [
      "df.correlation()",
      "df.corr()"
    ],
    "correctAnswer": 1,
    "explanation": "df.corr()은 상관계수 행렬을 계산하는 메서드입니다. df.correlation()은 존재하지 않는 메서드입니다.",
    "code": "corr_matrix = df.corr()",
    "difficulty": "easy"
  },
  {
    "id": "q045",
    "category": "데이터 시각화",
    "question": "서브플롯을 생성하는 matplotlib 함수는?",
    "options": [
      "plt.sub()",
      "plt.subplot()"
    ],
    "correctAnswer": 1,
    "explanation": "plt.subplot()은 서브플롯을 생성하는 함수입니다. plt.sub()는 존재하지 않는 함수입니다.",
    "code": "plt.subplot(2, 2, 1)",
    "difficulty": "medium"
  },
  {
    "id": "q046",
    "category": "그룹화 및 집계",
    "question": "데이터를 그룹별로 집계하는 pandas 메서드는?",
    "options": [
      "df.group()",
      "df.groupby()"
    ],
    "correctAnswer": 1,
    "explanation": "df.groupby()는 데이터를 그룹별로 나누어 집계하는 메서드입니다. df.group()은 존재하지 않는 메서드입니다.",
    "code": "df.groupby('category').sum()",
    "difficulty": "easy"
  },
  {
    "id": "q047",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 인덱스를 컬럼으로 변환하는 메서드는?",
    "options": [
      "reset()",
      "reset_index()"
    ],
    "correctAnswer": 1,
    "explanation": "reset_index()는 그룹화 후 인덱스를 컬럼으로 변환합니다. reset()은 존재하지 않는 메서드입니다.",
    "code": "result = df.groupby('category').sum().reset_index()",
    "difficulty": "medium"
  },
  {
    "id": "q048",
    "category": "그룹화 및 집계",
    "question": "여러 집계 함수를 동시에 적용하는 메서드는?",
    "options": [
      "aggregate()",
      "agg()"
    ],
    "correctAnswer": 1,
    "explanation": "agg()는 여러 집계 함수를 동시에 적용하는 메서드입니다. aggregate()도 동일하지만 agg()가 더 간단합니다.",
    "code": "df.groupby('category').agg({'value': ['mean', 'sum']})",
    "difficulty": "medium"
  },
  {
    "id": "q049",
    "category": "그룹화 및 집계",
    "question": "그룹별 개수를 세는 메서드는?",
    "options": [
      "size()",
      "count()"
    ],
    "correctAnswer": 0,
    "explanation": "size()는 그룹별 개수를 세는 메서드입니다. count()는 결측치를 제외한 개수를 세는 메서드입니다.",
    "code": "df.groupby('category').size()",
    "difficulty": "easy"
  },
  {
    "id": "q050",
    "category": "그룹화 및 집계",
    "question": "값의 빈도를 계산하는 메서드는?",
    "options": [
      "freq()",
      "value_counts()"
    ],
    "correctAnswer": 1,
    "explanation": "value_counts()는 값의 빈도를 계산하는 메서드입니다. freq()는 존재하지 않는 메서드입니다.",
    "code": "df['category'].value_counts()",
    "difficulty": "easy"
  },
  {
    "id": "q051",
    "category": "그룹화 및 집계",
    "question": "상대적 비율을 계산할 때 사용하는 파라미터는?",
    "options": [
      "ratio=True",
      "normalize=True"
    ],
    "correctAnswer": 1,
    "explanation": "value_counts(normalize=True)로 상대적 비율을 계산할 수 있습니다. ratio=True는 존재하지 않는 파라미터입니다.",
    "code": "df['category'].value_counts(normalize=True)",
    "difficulty": "medium"
  },
  {
    "id": "q052",
    "category": "그룹화 및 집계",
    "question": "데이터를 정렬하는 메서드는?",
    "options": [
      "sort()",
      "sort_values()"
    ],
    "correctAnswer": 1,
    "explanation": "sort_values()는 데이터를 정렬하는 메서드입니다. sort()는 존재하지 않는 메서드입니다.",
    "code": "df.sort_values('value', ascending=False)",
    "difficulty": "easy"
  },
  {
    "id": "q053",
    "category": "그룹화 및 집계",
    "question": "상위 N개를 선택하는 메서드는?",
    "options": [
      "top()",
      "head()"
    ],
    "correctAnswer": 1,
    "explanation": "head()는 상위 N개를 선택하는 메서드입니다. top()은 존재하지 않는 메서드입니다.",
    "code": "df.head(10)",
    "difficulty": "easy"
  },
  {
    "id": "q054",
    "category": "그룹화 및 집계",
    "question": "가장 큰 값들을 선택하는 메서드는?",
    "options": [
      "nlargest()",
      "max()"
    ],
    "correctAnswer": 0,
    "explanation": "nlargest()는 가장 큰 값들을 선택하는 메서드입니다. max()는 최댓값 하나만 반환합니다.",
    "code": "df.nlargest(5, 'value')",
    "difficulty": "medium"
  },
  {
    "id": "q055",
    "category": "그룹화 및 집계",
    "question": "가장 작은 값들을 선택하는 메서드는?",
    "options": [
      "nsmallest()",
      "min()"
    ],
    "correctAnswer": 0,
    "explanation": "nsmallest()는 가장 작은 값들을 선택하는 메서드입니다. min()은 최솟값 하나만 반환합니다.",
    "code": "df.nsmallest(5, 'value')",
    "difficulty": "medium"
  },
  {
    "id": "q056",
    "category": "데이터 전처리",
    "question": "날짜 문자열을 datetime으로 변환하는 pandas 함수는?",
    "options": [
      "pd.to_datetime()",
      "pd.datetime()"
    ],
    "correctAnswer": 0,
    "explanation": "pd.to_datetime()은 날짜 문자열을 datetime 객체로 변환하는 함수입니다. pd.datetime()은 존재하지 않는 함수입니다.",
    "code": "df['date'] = pd.to_datetime(df['date'])",
    "difficulty": "easy"
  },
  {
    "id": "q057",
    "category": "데이터 전처리",
    "question": "datetime에서 연도를 추출하는 속성은?",
    "options": [
      "dt.Year",
      "dt.year"
    ],
    "correctAnswer": 1,
    "explanation": "dt.year는 datetime에서 연도를 추출하는 속성입니다. dt.Year는 존재하지 않는 속성입니다.",
    "code": "df['year'] = df['date'].dt.year",
    "difficulty": "easy"
  },
  {
    "id": "q058",
    "category": "데이터 전처리",
    "question": "datetime에서 월을 추출하는 속성은?",
    "options": [
      "dt.month",
      "dt.Month"
    ],
    "correctAnswer": 0,
    "explanation": "dt.month는 datetime에서 월을 추출하는 속성입니다. dt.Month는 존재하지 않는 속성입니다.",
    "code": "df['month'] = df['date'].dt.month",
    "difficulty": "easy"
  },
  {
    "id": "q059",
    "category": "데이터 전처리",
    "question": "datetime에서 요일을 추출하는 속성은?",
    "options": [
      "dt.weekday",
      "dt.dayofweek"
    ],
    "correctAnswer": 1,
    "explanation": "dt.dayofweek는 요일을 숫자로 반환합니다 (0=월요일). dt.weekday도 동일하지만 dt.dayofweek가 더 일반적입니다.",
    "code": "df['weekday'] = df['date'].dt.dayofweek",
    "difficulty": "medium"
  },
  {
    "id": "q060",
    "category": "데이터 전처리",
    "question": "문자열을 대문자로 변환하는 메서드는?",
    "options": [
      "str.uppercase()",
      "str.upper()"
    ],
    "correctAnswer": 1,
    "explanation": "str.upper()는 문자열을 대문자로 변환하는 메서드입니다. str.uppercase()는 존재하지 않는 메서드입니다.",
    "code": "df['name_upper'] = df['name'].str.upper()",
    "difficulty": "easy"
  },
  {
    "id": "q061",
    "category": "데이터 전처리",
    "question": "문자열을 소문자로 변환하는 메서드는?",
    "options": [
      "str.lower()",
      "str.lowercase()"
    ],
    "correctAnswer": 0,
    "explanation": "str.lower()는 문자열을 소문자로 변환하는 메서드입니다. str.lowercase()는 존재하지 않는 메서드입니다.",
    "code": "df['name_lower'] = df['name'].str.lower()",
    "difficulty": "easy"
  },
  {
    "id": "q062",
    "category": "데이터 전처리",
    "question": "문자열의 길이를 구하는 메서드는?",
    "options": [
      "str.len()",
      "str.length()"
    ],
    "correctAnswer": 0,
    "explanation": "str.len()는 문자열의 길이를 구하는 메서드입니다. str.length()는 존재하지 않는 메서드입니다.",
    "code": "df['name_length'] = df['name'].str.len()",
    "difficulty": "easy"
  },
  {
    "id": "q063",
    "category": "데이터 전처리",
    "question": "조건에 따라 값을 선택하는 numpy 함수는?",
    "options": [
      "np.where()",
      "np.if()"
    ],
    "correctAnswer": 0,
    "explanation": "np.where()는 조건에 따라 값을 선택하는 함수입니다. np.if()는 존재하지 않는 함수입니다.",
    "code": "df['category'] = np.where(df['value'] > 100, 'high', 'low')",
    "difficulty": "medium"
  },
  {
    "id": "q064",
    "category": "데이터 전처리",
    "question": "데이터 타입을 변환하는 메서드는?",
    "options": [
      "astype()",
      "convert()"
    ],
    "correctAnswer": 0,
    "explanation": "astype()는 데이터 타입을 변환하는 메서드입니다. convert()는 존재하지 않는 메서드입니다.",
    "code": "df['category'] = df['category'].astype('category')",
    "difficulty": "easy"
  },
  {
    "id": "q065",
    "category": "데이터 전처리",
    "question": "0을 NaN으로 변환하는 메서드는?",
    "options": [
      "replace(0, np.nan)",
      "fillna(0)"
    ],
    "correctAnswer": 0,
    "explanation": "replace(0, np.nan)은 0을 NaN으로 변환합니다. fillna(0)은 NaN을 0으로 채웁니다.",
    "code": "df['value'] = df['value'].replace(0, np.nan)",
    "difficulty": "medium"
  },
  {
    "id": "q066",
    "category": "결측치 처리",
    "question": "결측치를 확인하는 메서드는?",
    "options": [
      "isnull()",
      "isna()"
    ],
    "correctAnswer": 0,
    "explanation": "isnull()과 isna()는 동일한 기능을 수행합니다. isnull()이 더 일반적으로 사용됩니다.",
    "code": "df.isnull().sum()",
    "difficulty": "easy"
  },
  {
    "id": "q067",
    "category": "결측치 처리",
    "question": "결측치를 중앙값으로 채우는 메서드는?",
    "options": [
      "fillna(df.median())",
      "fillna(median)"
    ],
    "correctAnswer": 0,
    "explanation": "fillna(df.median())은 결측치를 중앙값으로 채웁니다. fillna(median)은 median이 정의되지 않은 변수입니다.",
    "code": "df['value'] = df['value'].fillna(df['value'].median())",
    "difficulty": "medium"
  },
  {
    "id": "q068",
    "category": "결측치 처리",
    "question": "결측치를 평균값으로 채우는 메서드는?",
    "options": [
      "fillna(mean)",
      "fillna(df.mean())"
    ],
    "correctAnswer": 1,
    "explanation": "fillna(df.mean())은 결측치를 평균값으로 채웁니다. fillna(mean)은 mean이 정의되지 않은 변수입니다.",
    "code": "df['value'] = df['value'].fillna(df['value'].mean())",
    "difficulty": "medium"
  },
  {
    "id": "q069",
    "category": "결측치 처리",
    "question": "결측치를 최빈값으로 채우는 메서드는?",
    "options": [
      "fillna(df.mode())",
      "fillna(df.mode().iloc[0])"
    ],
    "correctAnswer": 1,
    "explanation": "fillna(df.mode().iloc[0])은 결측치를 최빈값으로 채웁니다. mode()는 Series를 반환하므로 iloc[0]으로 첫 번째 값을 가져와야 합니다.",
    "code": "df['category'] = df['category'].fillna(df['category'].mode().iloc[0])",
    "difficulty": "hard"
  },
  {
    "id": "q070",
    "category": "결측치 처리",
    "question": "결측치가 있는 행을 삭제하는 메서드는?",
    "options": [
      "remove_na()",
      "dropna()"
    ],
    "correctAnswer": 1,
    "explanation": "dropna()는 결측치가 있는 행을 삭제하는 메서드입니다. remove_na()는 존재하지 않는 메서드입니다.",
    "code": "df_clean = df.dropna()",
    "difficulty": "easy"
  },
  {
    "id": "q071",
    "category": "결측치 처리",
    "question": "특정 컬럼의 결측치가 있는 행만 삭제하는 파라미터는?",
    "options": [
      "columns",
      "subset"
    ],
    "correctAnswer": 1,
    "explanation": "dropna(subset=['column'])은 특정 컬럼의 결측치가 있는 행만 삭제합니다. columns는 존재하지 않는 파라미터입니다.",
    "code": "df_clean = df.dropna(subset=['important_column'])",
    "difficulty": "medium"
  },
  {
    "id": "q072",
    "category": "결측치 처리",
    "question": "결측치를 앞의 값으로 채우는 메서드는?",
    "options": [
      "fillna(method='ffill')",
      "fillna(method='forward')"
    ],
    "correctAnswer": 0,
    "explanation": "fillna(method='ffill')은 결측치를 앞의 값으로 채웁니다. method='forward'는 존재하지 않는 옵션입니다.",
    "code": "df['value'] = df['value'].fillna(method='ffill')",
    "difficulty": "medium"
  },
  {
    "id": "q073",
    "category": "결측치 처리",
    "question": "결측치를 뒤의 값으로 채우는 메서드는?",
    "options": [
      "fillna(method='bfill')",
      "fillna(method='backward')"
    ],
    "correctAnswer": 0,
    "explanation": "fillna(method='bfill')은 결측치를 뒤의 값으로 채웁니다. method='backward'는 존재하지 않는 옵션입니다.",
    "code": "df['value'] = df['value'].fillna(method='bfill')",
    "difficulty": "medium"
  },
  {
    "id": "q074",
    "category": "결측치 처리",
    "question": "결측치를 보간하는 메서드는?",
    "options": [
      "interpol()",
      "interpolate()"
    ],
    "correctAnswer": 1,
    "explanation": "interpolate()는 결측치를 보간하는 메서드입니다. interpol()는 존재하지 않는 메서드입니다.",
    "code": "df['value'] = df['value'].interpolate()",
    "difficulty": "hard"
  },
  {
    "id": "q075",
    "category": "결측치 처리",
    "question": "결측치 비율을 계산하는 방법은?",
    "options": [
      "df.isnull().sum() / len(df)",
      "df.isnull().mean()"
    ],
    "correctAnswer": 1,
    "explanation": "df.isnull().mean()은 결측치 비율을 계산하는 더 간단한 방법입니다. mean()은 자동으로 비율을 계산합니다.",
    "code": "missing_ratio = df.isnull().mean()",
    "difficulty": "medium"
  },
  {
    "id": "q076",
    "category": "범주형 인코딩",
    "question": "범주형 데이터를 원-핫 인코딩하는 pandas 함수는?",
    "options": [
      "pd.onehot()",
      "pd.get_dummies()"
    ],
    "correctAnswer": 1,
    "explanation": "pd.get_dummies()는 범주형 데이터를 원-핫 인코딩하는 함수입니다. pd.onehot()는 존재하지 않는 함수입니다.",
    "code": "df_encoded = pd.get_dummies(df, columns=['category'])",
    "difficulty": "easy"
  },
  {
    "id": "q077",
    "category": "범주형 인코딩",
    "question": "sklearn에서 원-핫 인코딩을 수행하는 클래스는?",
    "options": [
      "OneHotEncoder",
      "OneHot"
    ],
    "correctAnswer": 0,
    "explanation": "OneHotEncoder는 sklearn에서 원-핫 인코딩을 수행하는 클래스입니다. OneHot은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import OneHotEncoder",
    "difficulty": "medium"
  },
  {
    "id": "q078",
    "category": "범주형 인코딩",
    "question": "라벨 인코딩을 수행하는 sklearn 클래스는?",
    "options": [
      "Label",
      "LabelEncoder"
    ],
    "correctAnswer": 1,
    "explanation": "LabelEncoder는 라벨 인코딩을 수행하는 sklearn 클래스입니다. Label은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import LabelEncoder",
    "difficulty": "medium"
  },
  {
    "id": "q079",
    "category": "범주형 인코딩",
    "question": "OneHotEncoder에서 새로운 범주를 처리하는 파라미터는?",
    "options": [
      "unknown='ignore'",
      "handle_unknown='ignore'"
    ],
    "correctAnswer": 1,
    "explanation": "handle_unknown='ignore'는 새로운 범주를 무시하도록 설정하는 파라미터입니다. unknown='ignore'는 존재하지 않는 파라미터입니다.",
    "code": "ohe = OneHotEncoder(handle_unknown='ignore')",
    "difficulty": "hard"
  },
  {
    "id": "q080",
    "category": "범주형 인코딩",
    "question": "get_dummies에서 첫 번째 더미 변수를 제거하는 파라미터는?",
    "options": [
      "remove_first=True",
      "drop_first=True"
    ],
    "correctAnswer": 1,
    "explanation": "drop_first=True는 첫 번째 더미 변수를 제거하여 다중공선성을 방지합니다. remove_first=True는 존재하지 않는 파라미터입니다.",
    "code": "df_encoded = pd.get_dummies(df, columns=['category'], drop_first=True)",
    "difficulty": "medium"
  },
  {
    "id": "q081",
    "category": "데이터셋 분리",
    "question": "데이터를 훈련/테스트로 분리하는 sklearn 함수는?",
    "options": [
      "train_test_split",
      "split_data"
    ],
    "correctAnswer": 0,
    "explanation": "train_test_split은 데이터를 훈련/테스트로 분리하는 sklearn 함수입니다. split_data는 존재하지 않는 함수입니다.",
    "code": "from sklearn.model_selection import train_test_split",
    "difficulty": "easy"
  },
  {
    "id": "q082",
    "category": "데이터셋 분리",
    "question": "train_test_split에서 테스트셋 비율을 설정하는 파라미터는?",
    "options": [
      "test_ratio",
      "test_size"
    ],
    "correctAnswer": 1,
    "explanation": "test_size는 테스트셋 비율을 설정하는 파라미터입니다. test_ratio는 존재하지 않는 파라미터입니다.",
    "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)",
    "difficulty": "easy"
  },
  {
    "id": "q083",
    "category": "데이터셋 분리",
    "question": "train_test_split에서 재현성을 위한 파라미터는?",
    "options": [
      "random_state",
      "seed"
    ],
    "correctAnswer": 0,
    "explanation": "random_state는 재현성을 위한 파라미터입니다. seed는 존재하지 않는 파라미터입니다.",
    "code": "train_test_split(X, y, random_state=42)",
    "difficulty": "easy"
  },
  {
    "id": "q084",
    "category": "데이터셋 분리",
    "question": "클래스 비율을 유지하는 파라미터는?",
    "options": [
      "stratify",
      "balance"
    ],
    "correctAnswer": 0,
    "explanation": "stratify는 클래스 비율을 유지하는 파라미터입니다. balance는 존재하지 않는 파라미터입니다.",
    "code": "train_test_split(X, y, stratify=y)",
    "difficulty": "medium"
  },
  {
    "id": "q085",
    "category": "데이터셋 분리",
    "question": "시계열 데이터를 분리할 때 사용하는 방법은?",
    "options": [
      "랜덤 분할",
      "순차 분할"
    ],
    "correctAnswer": 1,
    "explanation": "시계열 데이터는 시간 순서를 유지해야 하므로 순차 분할을 사용해야 합니다. 랜덤 분할은 미래 정보 누수를 야기할 수 있습니다.",
    "code": "split_idx = int(len(df) * 0.8)\ntrain, test = df[:split_idx], df[split_idx:]",
    "difficulty": "medium"
  },
  {
    "id": "q086",
    "category": "스케일링",
    "question": "표준화를 수행하는 sklearn 클래스는?",
    "options": [
      "StandardScale",
      "StandardScaler"
    ],
    "correctAnswer": 1,
    "explanation": "StandardScaler는 표준화를 수행하는 sklearn 클래스입니다. StandardScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import StandardScaler",
    "difficulty": "easy"
  },
  {
    "id": "q087",
    "category": "스케일링",
    "question": "정규화를 수행하는 sklearn 클래스는?",
    "options": [
      "MinMaxScaler",
      "MinMaxScale"
    ],
    "correctAnswer": 0,
    "explanation": "MinMaxScaler는 정규화를 수행하는 sklearn 클래스입니다. MinMaxScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import MinMaxScaler",
    "difficulty": "easy"
  },
  {
    "id": "q088",
    "category": "스케일링",
    "question": "이상치에 강한 스케일링을 수행하는 sklearn 클래스는?",
    "options": [
      "RobustScaler",
      "RobustScale"
    ],
    "correctAnswer": 0,
    "explanation": "RobustScaler는 이상치에 강한 스케일링을 수행하는 sklearn 클래스입니다. RobustScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import RobustScaler",
    "difficulty": "medium"
  },
  {
    "id": "q089",
    "category": "스케일링",
    "question": "스케일러를 훈련시키는 메서드는?",
    "options": [
      "train()",
      "fit()"
    ],
    "correctAnswer": 1,
    "explanation": "fit()은 스케일러를 훈련시키는 메서드입니다. train()은 존재하지 않는 메서드입니다.",
    "code": "scaler.fit(X_train)",
    "difficulty": "easy"
  },
  {
    "id": "q090",
    "category": "스케일링",
    "question": "스케일러를 적용하는 메서드는?",
    "options": [
      "apply()",
      "transform()"
    ],
    "correctAnswer": 1,
    "explanation": "transform()은 스케일러를 적용하는 메서드입니다. apply()는 존재하지 않는 메서드입니다.",
    "code": "X_scaled = scaler.transform(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q091",
    "category": "기본 모델링",
    "question": "의사결정나무 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "DecisionTree",
      "DecisionTreeClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "DecisionTreeClassifier는 의사결정나무 분류기를 생성하는 sklearn 클래스입니다. DecisionTree는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.tree import DecisionTreeClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q092",
    "category": "기본 모델링",
    "question": "로지스틱 회귀를 수행하는 sklearn 클래스는?",
    "options": [
      "LogisticRegression",
      "LogisticReg"
    ],
    "correctAnswer": 0,
    "explanation": "LogisticRegression은 로지스틱 회귀를 수행하는 sklearn 클래스입니다. LogisticReg는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.linear_model import LogisticRegression",
    "difficulty": "easy"
  },
  {
    "id": "q093",
    "category": "기본 모델링",
    "question": "K-최근접 이웃 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "KNeighborsClassifier",
      "KNeighbors"
    ],
    "correctAnswer": 0,
    "explanation": "KNeighborsClassifier는 K-최근접 이웃 분류기를 생성하는 sklearn 클래스입니다. KNeighbors는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.neighbors import KNeighborsClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q094",
    "category": "기본 모델링",
    "question": "모델을 학습시키는 메서드는?",
    "options": [
      "train()",
      "fit()"
    ],
    "correctAnswer": 1,
    "explanation": "fit()은 모델을 학습시키는 메서드입니다. train()은 존재하지 않는 메서드입니다.",
    "code": "model.fit(X_train, y_train)",
    "difficulty": "easy"
  },
  {
    "id": "q095",
    "category": "기본 모델링",
    "question": "모델로 예측을 수행하는 메서드는?",
    "options": [
      "forecast()",
      "predict()"
    ],
    "correctAnswer": 1,
    "explanation": "predict()은 모델로 예측을 수행하는 메서드입니다. forecast()는 존재하지 않는 메서드입니다.",
    "code": "y_pred = model.predict(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q096",
    "category": "앙상블 모델링",
    "question": "랜덤 포레스트 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "RandomForest",
      "RandomForestClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "RandomForestClassifier는 랜덤 포레스트 분류기를 생성하는 sklearn 클래스입니다. RandomForest는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.ensemble import RandomForestClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q097",
    "category": "앙상블 모델링",
    "question": "XGBoost 분류기를 생성하는 클래스는?",
    "options": [
      "XGBClassifier",
      "XGBoostClassifier"
    ],
    "correctAnswer": 0,
    "explanation": "XGBClassifier는 XGBoost 분류기를 생성하는 클래스입니다. XGBoostClassifier는 존재하지 않는 클래스입니다.",
    "code": "from xgboost import XGBClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q098",
    "category": "앙상블 모델링",
    "question": "RandomForest에서 트리의 개수를 설정하는 파라미터는?",
    "options": [
      "n_estimators",
      "n_trees"
    ],
    "correctAnswer": 0,
    "explanation": "n_estimators는 RandomForest에서 트리의 개수를 설정하는 파라미터입니다. n_trees는 존재하지 않는 파라미터입니다.",
    "code": "rf = RandomForestClassifier(n_estimators=100)",
    "difficulty": "medium"
  },
  {
    "id": "q099",
    "category": "앙상블 모델링",
    "question": "XGBoost에서 학습률을 설정하는 파라미터는?",
    "options": [
      "learning_rate",
      "lr"
    ],
    "correctAnswer": 0,
    "explanation": "learning_rate는 XGBoost에서 학습률을 설정하는 파라미터입니다. lr은 존재하지 않는 파라미터입니다.",
    "code": "xgb = XGBClassifier(learning_rate=0.1)",
    "difficulty": "medium"
  },
  {
    "id": "q100",
    "category": "앙상블 모델링",
    "question": "특성 중요도를 확인하는 속성은?",
    "options": [
      "feature_importances_",
      "feature_importance"
    ],
    "correctAnswer": 0,
    "explanation": "feature_importances_는 특성 중요도를 확인하는 속성입니다. feature_importance는 존재하지 않는 속성입니다.",
    "code": "importance = rf.feature_importances_",
    "difficulty": "medium"
  },
  {
    "id": "q101",
    "category": "모델 성능 평가",
    "question": "분류 모델의 정확도를 계산하는 sklearn 함수는?",
    "options": [
      "accuracy",
      "accuracy_score"
    ],
    "correctAnswer": 1,
    "explanation": "accuracy_score는 분류 모델의 정확도를 계산하는 sklearn 함수입니다. accuracy는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import accuracy_score",
    "difficulty": "easy"
  },
  {
    "id": "q102",
    "category": "모델 성능 평가",
    "question": "정밀도를 계산하는 sklearn 함수는?",
    "options": [
      "precision_score",
      "precision"
    ],
    "correctAnswer": 0,
    "explanation": "precision_score는 정밀도를 계산하는 sklearn 함수입니다. precision은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import precision_score",
    "difficulty": "medium"
  },
  {
    "id": "q103",
    "category": "모델 성능 평가",
    "question": "재현율을 계산하는 sklearn 함수는?",
    "options": [
      "recall_score",
      "recall"
    ],
    "correctAnswer": 0,
    "explanation": "recall_score는 재현율을 계산하는 sklearn 함수입니다. recall은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import recall_score",
    "difficulty": "medium"
  },
  {
    "id": "q104",
    "category": "모델 성능 평가",
    "question": "F1 점수를 계산하는 sklearn 함수는?",
    "options": [
      "f1_score",
      "f1"
    ],
    "correctAnswer": 0,
    "explanation": "f1_score는 F1 점수를 계산하는 sklearn 함수입니다. f1은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import f1_score",
    "difficulty": "medium"
  },
  {
    "id": "q105",
    "category": "모델 성능 평가",
    "question": "혼동행렬을 계산하는 sklearn 함수는?",
    "options": [
      "confusion",
      "confusion_matrix"
    ],
    "correctAnswer": 1,
    "explanation": "confusion_matrix는 혼동행렬을 계산하는 sklearn 함수입니다. confusion은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import confusion_matrix",
    "difficulty": "medium"
  },
  {
    "id": "q106",
    "category": "모델 성능 평가",
    "question": "분류 보고서를 출력하는 sklearn 함수는?",
    "options": [
      "classification_report",
      "class_report"
    ],
    "correctAnswer": 0,
    "explanation": "classification_report는 분류 보고서를 출력하는 sklearn 함수입니다. class_report는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import classification_report",
    "difficulty": "medium"
  },
  {
    "id": "q107",
    "category": "모델 성능 평가",
    "question": "회귀 모델의 평균 절대 오차를 계산하는 sklearn 함수는?",
    "options": [
      "mae",
      "mean_absolute_error"
    ],
    "correctAnswer": 1,
    "explanation": "mean_absolute_error는 회귀 모델의 평균 절대 오차를 계산하는 sklearn 함수입니다. mae는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import mean_absolute_error",
    "difficulty": "medium"
  },
  {
    "id": "q108",
    "category": "모델 성능 평가",
    "question": "회귀 모델의 평균 제곱 오차를 계산하는 sklearn 함수는?",
    "options": [
      "mse",
      "mean_squared_error"
    ],
    "correctAnswer": 1,
    "explanation": "mean_squared_error는 회귀 모델의 평균 제곱 오차를 계산하는 sklearn 함수입니다. mse는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import mean_squared_error",
    "difficulty": "medium"
  },
  {
    "id": "q109",
    "category": "모델 성능 평가",
    "question": "RMSE를 계산하는 방법은?",
    "options": [
      "rmse()",
      "np.sqrt(mean_squared_error())"
    ],
    "correctAnswer": 1,
    "explanation": "RMSE는 MSE의 제곱근이므로 np.sqrt(mean_squared_error())로 계산합니다. rmse()는 존재하지 않는 함수입니다.",
    "code": "rmse = np.sqrt(mean_squared_error(y_test, y_pred))",
    "difficulty": "hard"
  },
  {
    "id": "q110",
    "category": "모델 성능 평가",
    "question": "R² 점수를 계산하는 sklearn 함수는?",
    "options": [
      "r2_score",
      "r2"
    ],
    "correctAnswer": 0,
    "explanation": "r2_score는 R² 점수를 계산하는 sklearn 함수입니다. r2는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import r2_score",
    "difficulty": "medium"
  },
  {
    "id": "q111",
    "category": "딥러닝 모델 구성",
    "question": "Keras Sequential 모델을 생성하는 방법은?",
    "options": [
      "keras.Sequential()",
      "keras.Model()"
    ],
    "correctAnswer": 0,
    "explanation": "keras.Sequential()은 순차적 레이어를 쌓는 모델을 생성합니다. keras.Model()은 함수형 API용입니다.",
    "code": "model = keras.Sequential()",
    "difficulty": "easy"
  },
  {
    "id": "q112",
    "category": "딥러닝 모델 구성",
    "question": "완전연결 레이어를 추가하는 Keras 클래스는?",
    "options": [
      "keras.layers.FullyConnected",
      "keras.layers.Dense"
    ],
    "correctAnswer": 1,
    "explanation": "keras.layers.Dense는 완전연결 레이어를 추가하는 Keras 클래스입니다. FullyConnected는 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Dense(64, activation='relu')",
    "difficulty": "easy"
  },
  {
    "id": "q113",
    "category": "딥러닝 모델 구성",
    "question": "드롭아웃 레이어를 추가하는 Keras 클래스는?",
    "options": [
      "keras.layers.Dropout",
      "keras.layers.Drop"
    ],
    "correctAnswer": 0,
    "explanation": "keras.layers.Dropout은 드롭아웃 레이어를 추가하는 Keras 클래스입니다. Drop은 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Dropout(0.2)",
    "difficulty": "easy"
  },
  {
    "id": "q114",
    "category": "딥러닝 모델 구성",
    "question": "입력 레이어를 정의하는 Keras 클래스는?",
    "options": [
      "keras.layers.InputLayer",
      "keras.layers.Input"
    ],
    "correctAnswer": 1,
    "explanation": "keras.layers.Input은 입력 레이어를 정의하는 Keras 클래스입니다. InputLayer는 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Input(shape=(input_dim,))",
    "difficulty": "medium"
  },
  {
    "id": "q115",
    "category": "딥러닝 모델 구성",
    "question": "모델을 컴파일하는 메서드는?",
    "options": [
      "compile()",
      "build()"
    ],
    "correctAnswer": 0,
    "explanation": "compile()은 모델을 컴파일하는 메서드입니다. build()는 존재하지 않는 메서드입니다.",
    "code": "model.compile(optimizer='adam', loss='binary_crossentropy')",
    "difficulty": "easy"
  },
  {
    "id": "q116",
    "category": "딥러닝 모델 구성",
    "question": "이진 분류에서 사용하는 손실 함수는?",
    "options": [
      "binary_crossentropy",
      "binary_cross"
    ],
    "correctAnswer": 0,
    "explanation": "binary_crossentropy는 이진 분류에서 사용하는 손실 함수입니다. binary_cross는 존재하지 않는 함수입니다.",
    "code": "model.compile(loss='binary_crossentropy')",
    "difficulty": "medium"
  },
  {
    "id": "q117",
    "category": "딥러닝 모델 구성",
    "question": "회귀에서 사용하는 손실 함수는?",
    "options": [
      "mean_squared_error",
      "mse"
    ],
    "correctAnswer": 1,
    "explanation": "mse는 회귀에서 사용하는 손실 함수입니다. mean_squared_error는 sklearn 함수명입니다.",
    "code": "model.compile(loss='mse')",
    "difficulty": "medium"
  },
  {
    "id": "q118",
    "category": "딥러닝 모델 구성",
    "question": "Adam 옵티마이저를 사용하는 방법은?",
    "options": [
      "optimizer='adam'",
      "optimizer=Adam()"
    ],
    "correctAnswer": 0,
    "explanation": "optimizer='adam'은 Adam 옵티마이저를 사용하는 간단한 방법입니다. optimizer=Adam()도 가능하지만 더 복잡합니다.",
    "code": "model.compile(optimizer='adam')",
    "difficulty": "easy"
  },
  {
    "id": "q119",
    "category": "딥러닝 모델 구성",
    "question": "모델을 학습시키는 메서드는?",
    "options": [
      "fit()",
      "train()"
    ],
    "correctAnswer": 0,
    "explanation": "fit()은 모델을 학습시키는 메서드입니다. train()은 존재하지 않는 메서드입니다.",
    "code": "history = model.fit(X_train, y_train, epochs=100)",
    "difficulty": "easy"
  },
  {
    "id": "q120",
    "category": "딥러닝 모델 구성",
    "question": "EarlyStopping 콜백을 생성하는 Keras 클래스는?",
    "options": [
      "keras.EarlyStopping",
      "keras.callbacks.EarlyStopping"
    ],
    "correctAnswer": 1,
    "explanation": "keras.callbacks.EarlyStopping은 EarlyStopping 콜백을 생성하는 Keras 클래스입니다. keras.EarlyStopping은 존재하지 않는 클래스입니다.",
    "code": "from keras.callbacks import EarlyStopping",
    "difficulty": "medium"
  },
  {
    "id": "q121",
    "category": "딥러닝 평가 및 시각화",
    "question": "학습 과정을 시각화하는 방법은?",
    "options": [
      "plt.plot(history.history['loss'])",
      "plt.plot(history.loss)"
    ],
    "correctAnswer": 0,
    "explanation": "history.history['loss']는 학습 과정의 손실을 저장하는 딕셔너리입니다. history.loss는 존재하지 않는 속성입니다.",
    "code": "plt.plot(history.history['loss'])",
    "difficulty": "medium"
  },
  {
    "id": "q122",
    "category": "딥러닝 평가 및 시각화",
    "question": "검증 손실을 시각화하는 방법은?",
    "options": [
      "plt.plot(history.history['val_loss'])",
      "plt.plot(history.val_loss)"
    ],
    "correctAnswer": 0,
    "explanation": "history.history['val_loss']는 검증 손실을 저장하는 딕셔너리입니다. history.val_loss는 존재하지 않는 속성입니다.",
    "code": "plt.plot(history.history['val_loss'])",
    "difficulty": "medium"
  },
  {
    "id": "q123",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델을 저장하는 메서드는?",
    "options": [
      "model.save()",
      "model.store()"
    ],
    "correctAnswer": 0,
    "explanation": "model.save()는 모델을 저장하는 메서드입니다. model.store()는 존재하지 않는 메서드입니다.",
    "code": "model.save('model.keras')",
    "difficulty": "easy"
  },
  {
    "id": "q124",
    "category": "딥러닝 평가 및 시각화",
    "question": "저장된 모델을 로드하는 함수는?",
    "options": [
      "keras.models.load_model()",
      "keras.load_model()"
    ],
    "correctAnswer": 0,
    "explanation": "keras.models.load_model()은 저장된 모델을 로드하는 함수입니다. keras.load_model()은 존재하지 않는 함수입니다.",
    "code": "model = keras.models.load_model('model.keras')",
    "difficulty": "easy"
  },
  {
    "id": "q125",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델로 예측을 수행하는 메서드는?",
    "options": [
      "model.forecast()",
      "model.predict()"
    ],
    "correctAnswer": 1,
    "explanation": "model.predict()는 모델로 예측을 수행하는 메서드입니다. model.forecast()는 존재하지 않는 메서드입니다.",
    "code": "y_pred = model.predict(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q126",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델의 요약을 출력하는 메서드는?",
    "options": [
      "model.info()",
      "model.summary()"
    ],
    "correctAnswer": 1,
    "explanation": "model.summary()는 모델의 요약을 출력하는 메서드입니다. model.info()는 존재하지 않는 메서드입니다.",
    "code": "model.summary()",
    "difficulty": "easy"
  },
  {
    "id": "q127",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델의 파라미터 개수를 확인하는 메서드는?",
    "options": [
      "model.num_params()",
      "model.count_params()"
    ],
    "correctAnswer": 1,
    "explanation": "model.count_params()는 모델의 파라미터 개수를 확인하는 메서드입니다. model.num_params()는 존재하지 않는 메서드입니다.",
    "code": "print(model.count_params())",
    "difficulty": "medium"
  },
  {
    "id": "q128",
    "category": "딥러닝 평가 및 시각화",
    "question": "학습률을 조정하는 방법은?",
    "options": [
      "optimizer=keras.optimizers.Adam(learning_rate=0.001)",
      "optimizer='adam', lr=0.001"
    ],
    "correctAnswer": 0,
    "explanation": "keras.optimizers.Adam(learning_rate=0.001)로 학습률을 조정할 수 있습니다. lr 파라미터는 존재하지 않습니다.",
    "code": "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))",
    "difficulty": "hard"
  },
  {
    "id": "q129",
    "category": "딥러닝 평가 및 시각화",
    "question": "배치 정규화 레이어를 추가하는 Keras 클래스는?",
    "options": [
      "keras.layers.BatchNormalization",
      "keras.layers.BatchNorm"
    ],
    "correctAnswer": 0,
    "explanation": "keras.layers.BatchNormalization은 배치 정규화 레이어를 추가하는 Keras 클래스입니다. BatchNorm은 존재하지 않는 클래스입니다.",
    "code": "keras.layers.BatchNormalization()",
    "difficulty": "hard"
  },
  {
    "id": "q130",
    "category": "딥러닝 평가 및 시각화",
    "question": "콜백을 사용하여 모델을 학습시키는 방법은?",
    "options": [
      "model.fit(..., callbacks=[callback])",
      "model.fit(..., callback=callback)"
    ],
    "correctAnswer": 0,
    "explanation": "callbacks=[callback]로 콜백을 전달합니다. callback=callback은 존재하지 않는 파라미터입니다.",
    "code": "model.fit(X_train, y_train, callbacks=[early_stopping])",
    "difficulty": "medium"
  },
  {
    "id": "q131",
    "category": "라이브러리 임포트",
    "question": "경고 메시지를 억제하는 방법은?",
    "options": [
      "warnings.suppress()",
      "warnings.filterwarnings('ignore')"
    ],
    "correctAnswer": 1,
    "explanation": "warnings.filterwarnings('ignore')는 경고 메시지를 억제하는 방법입니다. warnings.suppress()는 존재하지 않는 함수입니다.",
    "code": "import warnings\nwarnings.filterwarnings('ignore')",
    "difficulty": "easy"
  },
  {
    "id": "q132",
    "category": "라이브러리 임포트",
    "question": "TensorFlow GPU 사용을 확인하는 방법은?",
    "options": [
      "tf.gpu.list_devices()",
      "tf.config.list_physical_devices('GPU')"
    ],
    "correctAnswer": 1,
    "explanation": "tf.config.list_physical_devices('GPU')는 TensorFlow GPU 사용을 확인하는 방법입니다. tf.gpu.list_devices()는 존재하지 않는 함수입니다.",
    "code": "print(tf.config.list_physical_devices('GPU'))",
    "difficulty": "hard"
  },
  {
    "id": "q133",
    "category": "라이브러리 임포트",
    "question": "sklearn에서 datasets를 임포트하는 방법은?",
    "options": [
      "from sklearn import datasets",
      "import sklearn.datasets"
    ],
    "correctAnswer": 0,
    "explanation": "from sklearn import datasets는 sklearn에서 datasets를 임포트하는 방법입니다. import sklearn.datasets는 존재하지 않는 방법입니다.",
    "code": "from sklearn import datasets",
    "difficulty": "easy"
  },
  {
    "id": "q134",
    "category": "라이브러리 임포트",
    "question": "pandas에서 Excel 파일을 읽기 위해 필요한 라이브러리는?",
    "options": [
      "openpyxl",
      "xlrd"
    ],
    "correctAnswer": 0,
    "explanation": "openpyxl은 pandas에서 Excel 파일을 읽기 위해 필요한 라이브러리입니다. xlrd는 구형 xls 파일용입니다.",
    "code": "pip install openpyxl",
    "difficulty": "medium"
  },
  {
    "id": "q135",
    "category": "라이브러리 임포트",
    "question": "matplotlib에서 한글 폰트를 설정하는 방법은?",
    "options": [
      "plt.font('NanumGothicCoding')",
      "plt.rc('font', family='NanumGothicCoding')"
    ],
    "correctAnswer": 1,
    "explanation": "plt.rc('font', family='NanumGothicCoding')는 matplotlib에서 한글 폰트를 설정하는 방법입니다. plt.font()는 존재하지 않는 함수입니다.",
    "code": "plt.rc('font', family='NanumGothicCoding')",
    "difficulty": "medium"
  },
  {
    "id": "q136",
    "category": "데이터 불러오기",
    "question": "CSV 파일에서 구분자가 세미콜론일 때 사용하는 파라미터는?",
    "options": [
      "delimiter=';'",
      "sep=';'"
    ],
    "correctAnswer": 1,
    "explanation": "sep=';'는 CSV 파일에서 구분자가 세미콜론일 때 사용하는 파라미터입니다. delimiter=';'도 가능하지만 sep이 더 일반적입니다.",
    "code": "df = pd.read_csv('file.csv', sep=';')",
    "difficulty": "medium"
  },
  {
    "id": "q137",
    "category": "데이터 불러오기",
    "question": "CSV 파일에서 첫 번째 행을 인덱스로 사용할 때 사용하는 파라미터는?",
    "options": [
      "index=0",
      "index_col=0"
    ],
    "correctAnswer": 1,
    "explanation": "index_col=0은 CSV 파일에서 첫 번째 행을 인덱스로 사용할 때 사용하는 파라미터입니다. index=0은 존재하지 않는 파라미터입니다.",
    "code": "df = pd.read_csv('file.csv', index_col=0)",
    "difficulty": "medium"
  },
  {
    "id": "q138",
    "category": "데이터 불러오기",
    "question": "CSV 파일에서 특정 행을 건너뛸 때 사용하는 파라미터는?",
    "options": [
      "skiprows",
      "skip"
    ],
    "correctAnswer": 0,
    "explanation": "skiprows는 CSV 파일에서 특정 행을 건너뛸 때 사용하는 파라미터입니다. skip은 존재하지 않는 파라미터입니다.",
    "code": "df = pd.read_csv('file.csv', skiprows=1)",
    "difficulty": "medium"
  },
  {
    "id": "q139",
    "category": "데이터 불러오기",
    "question": "CSV 파일에서 특정 행 수만 읽을 때 사용하는 파라미터는?",
    "options": [
      "nrows",
      "rows"
    ],
    "correctAnswer": 0,
    "explanation": "nrows는 CSV 파일에서 특정 행 수만 읽을 때 사용하는 파라미터입니다. rows는 존재하지 않는 파라미터입니다.",
    "code": "df = pd.read_csv('file.csv', nrows=1000)",
    "difficulty": "medium"
  },
  {
    "id": "q140",
    "category": "데이터 불러오기",
    "question": "CSV 파일에서 결측치를 특정 값으로 표시할 때 사용하는 파라미터는?",
    "options": [
      "missing_values",
      "na_values"
    ],
    "correctAnswer": 1,
    "explanation": "na_values는 CSV 파일에서 결측치를 특정 값으로 표시할 때 사용하는 파라미터입니다. missing_values는 존재하지 않는 파라미터입니다.",
    "code": "df = pd.read_csv('file.csv', na_values=['', 'NULL'])",
    "difficulty": "hard"
  },
  {
    "id": "q141",
    "category": "데이터 시각화",
    "question": "seaborn에서 스타일을 설정하는 함수는?",
    "options": [
      "sns.style()",
      "sns.set_style()"
    ],
    "correctAnswer": 1,
    "explanation": "sns.set_style()은 seaborn에서 스타일을 설정하는 함수입니다. sns.style()은 존재하지 않는 함수입니다.",
    "code": "sns.set_style('whitegrid')",
    "difficulty": "easy"
  },
  {
    "id": "q142",
    "category": "데이터 시각화",
    "question": "seaborn에서 팔레트를 설정하는 함수는?",
    "options": [
      "sns.set_palette()",
      "sns.palette()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.set_palette()은 seaborn에서 팔레트를 설정하는 함수입니다. sns.palette()은 존재하지 않는 함수입니다.",
    "code": "sns.set_palette('husl')",
    "difficulty": "medium"
  },
  {
    "id": "q143",
    "category": "데이터 시각화",
    "question": "matplotlib에서 서브플롯을 생성하는 함수는?",
    "options": [
      "plt.subplot()",
      "plt.subplots()"
    ],
    "correctAnswer": 1,
    "explanation": "plt.subplots()는 matplotlib에서 서브플롯을 생성하는 함수입니다. plt.subplot()은 단일 서브플롯을 생성합니다.",
    "code": "fig, axes = plt.subplots(2, 2)",
    "difficulty": "medium"
  },
  {
    "id": "q144",
    "category": "데이터 시각화",
    "question": "seaborn에서 분포를 비교하는 함수는?",
    "options": [
      "sns.displot()",
      "sns.distplot()"
    ],
    "correctAnswer": 0,
    "explanation": "sns.displot()은 seaborn에서 분포를 비교하는 함수입니다. sns.distplot()은 deprecated되었습니다.",
    "code": "sns.displot(data=df, x='value', hue='category')",
    "difficulty": "medium"
  },
  {
    "id": "q145",
    "category": "데이터 시각화",
    "question": "seaborn에서 범주별 수치를 비교하는 함수는?",
    "options": [
      "sns.bar()",
      "sns.barplot()"
    ],
    "correctAnswer": 1,
    "explanation": "sns.barplot()은 seaborn에서 범주별 수치를 비교하는 함수입니다. sns.bar()은 존재하지 않는 함수입니다.",
    "code": "sns.barplot(data=df, x='category', y='value')",
    "difficulty": "easy"
  },
  {
    "id": "q146",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 여러 컬럼에 다른 집계 함수를 적용하는 방법은?",
    "options": [
      "df.groupby().apply({'col1': 'mean', 'col2': 'sum'})",
      "df.groupby().agg({'col1': 'mean', 'col2': 'sum'})"
    ],
    "correctAnswer": 1,
    "explanation": "agg() 메서드를 사용하여 여러 컬럼에 다른 집계 함수를 적용할 수 있습니다. apply()는 다른 용도입니다.",
    "code": "result = df.groupby('category').agg({'value1': 'mean', 'value2': 'sum'})",
    "difficulty": "medium"
  },
  {
    "id": "q147",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 컬럼명을 변경하는 방법은?",
    "options": [
      "reset_index(name='new_name')",
      "rename(columns={'old': 'new'})"
    ],
    "correctAnswer": 0,
    "explanation": "reset_index(name='new_name')은 그룹화 후 컬럼명을 변경하는 방법입니다. rename()은 다른 용도입니다.",
    "code": "result = df.groupby('category').sum().reset_index(name='total')",
    "difficulty": "medium"
  },
  {
    "id": "q148",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 상위 N개를 선택하는 방법은?",
    "options": [
      "df.groupby().apply(lambda x: x.nlargest(N))",
      "df.groupby().head(N)"
    ],
    "correctAnswer": 0,
    "explanation": "apply(lambda x: x.nlargest(N))은 그룹화 후 각 그룹에서 상위 N개를 선택하는 방법입니다. head(N)은 전체에서 상위 N개를 선택합니다.",
    "code": "result = df.groupby('category').apply(lambda x: x.nlargest(3, 'value'))",
    "difficulty": "hard"
  },
  {
    "id": "q149",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 누적합을 계산하는 방법은?",
    "options": [
      "df.groupby().sum().cumsum()",
      "df.groupby().cumsum()"
    ],
    "correctAnswer": 1,
    "explanation": "df.groupby().cumsum()은 그룹화 후 누적합을 계산하는 방법입니다. sum().cumsum()은 전체 누적합입니다.",
    "code": "df['cumsum'] = df.groupby('category')['value'].cumsum()",
    "difficulty": "hard"
  },
  {
    "id": "q150",
    "category": "그룹화 및 집계",
    "question": "그룹화 후 비율을 계산하는 방법은?",
    "options": [
      "df.groupby().apply(lambda x: x / x.sum())",
      "df.groupby().transform(lambda x: x / x.sum())"
    ],
    "correctAnswer": 1,
    "explanation": "transform(lambda x: x / x.sum())은 그룹화 후 비율을 계산하는 방법입니다. apply()는 다른 용도입니다.",
    "code": "df['ratio'] = df.groupby('category')['value'].transform(lambda x: x / x.sum())",
    "difficulty": "hard"
  },
  {
    "id": "q151",
    "category": "데이터 전처리",
    "question": "문자열에서 특정 패턴을 찾는 메서드는?",
    "options": [
      "str.contains()",
      "str.find()"
    ],
    "correctAnswer": 0,
    "explanation": "str.contains()는 문자열에서 특정 패턴을 찾는 메서드입니다. str.find()는 위치를 반환합니다.",
    "code": "df['has_pattern'] = df['text'].str.contains('pattern')",
    "difficulty": "medium"
  },
  {
    "id": "q152",
    "category": "데이터 전처리",
    "question": "문자열을 분할하는 메서드는?",
    "options": [
      "str.split()",
      "str.divide()"
    ],
    "correctAnswer": 0,
    "explanation": "str.split()은 문자열을 분할하는 메서드입니다. str.divide()는 존재하지 않는 메서드입니다.",
    "code": "df['parts'] = df['text'].str.split(' ')",
    "difficulty": "medium"
  },
  {
    "id": "q153",
    "category": "데이터 전처리",
    "question": "문자열에서 정규표현식을 사용하여 추출하는 메서드는?",
    "options": [
      "str.regex()",
      "str.extract()"
    ],
    "correctAnswer": 1,
    "explanation": "str.extract()는 문자열에서 정규표현식을 사용하여 추출하는 메서드입니다. str.regex()는 존재하지 않는 메서드입니다.",
    "code": "df['extracted'] = df['text'].str.extract(r'(\\d+)')",
    "difficulty": "hard"
  },
  {
    "id": "q154",
    "category": "데이터 전처리",
    "question": "문자열을 치환하는 메서드는?",
    "options": [
      "str.replace()",
      "str.substitute()"
    ],
    "correctAnswer": 0,
    "explanation": "str.replace()는 문자열을 치환하는 메서드입니다. str.substitute()는 존재하지 않는 메서드입니다.",
    "code": "df['new_text'] = df['text'].str.replace('old', 'new')",
    "difficulty": "easy"
  },
  {
    "id": "q155",
    "category": "데이터 전처리",
    "question": "문자열의 앞뒤 공백을 제거하는 메서드는?",
    "options": [
      "str.trim()",
      "str.strip()"
    ],
    "correctAnswer": 1,
    "explanation": "str.strip()은 문자열의 앞뒤 공백을 제거하는 메서드입니다. str.trim()은 존재하지 않는 메서드입니다.",
    "code": "df['clean_text'] = df['text'].str.strip()",
    "difficulty": "easy"
  },
  {
    "id": "q156",
    "category": "결측치 처리",
    "question": "결측치를 특정 값으로 채우는 메서드는?",
    "options": [
      "replace_na(value)",
      "fillna(value)"
    ],
    "correctAnswer": 1,
    "explanation": "fillna(value)는 결측치를 특정 값으로 채우는 메서드입니다. replace_na()는 존재하지 않는 메서드입니다.",
    "code": "df['value'] = df['value'].fillna(0)",
    "difficulty": "easy"
  },
  {
    "id": "q157",
    "category": "결측치 처리",
    "question": "결측치를 앞의 값으로 채우는 메서드는?",
    "options": [
      "fillna(method='forward')",
      "fillna(method='ffill')"
    ],
    "correctAnswer": 1,
    "explanation": "fillna(method='ffill')은 결측치를 앞의 값으로 채우는 메서드입니다. method='forward'는 존재하지 않는 옵션입니다.",
    "code": "df['value'] = df['value'].fillna(method='ffill')",
    "difficulty": "medium"
  },
  {
    "id": "q158",
    "category": "결측치 처리",
    "question": "결측치를 뒤의 값으로 채우는 메서드는?",
    "options": [
      "fillna(method='bfill')",
      "fillna(method='backward')"
    ],
    "correctAnswer": 0,
    "explanation": "fillna(method='bfill')은 결측치를 뒤의 값으로 채우는 메서드입니다. method='backward'는 존재하지 않는 옵션입니다.",
    "code": "df['value'] = df['value'].fillna(method='bfill')",
    "difficulty": "medium"
  },
  {
    "id": "q159",
    "category": "결측치 처리",
    "question": "결측치를 보간하는 메서드는?",
    "options": [
      "interpol()",
      "interpolate()"
    ],
    "correctAnswer": 1,
    "explanation": "interpolate()는 결측치를 보간하는 메서드입니다. interpol()는 존재하지 않는 메서드입니다.",
    "code": "df['value'] = df['value'].interpolate()",
    "difficulty": "hard"
  },
  {
    "id": "q160",
    "category": "결측치 처리",
    "question": "결측치가 있는 행을 삭제하는 메서드는?",
    "options": [
      "remove_na()",
      "dropna()"
    ],
    "correctAnswer": 1,
    "explanation": "dropna()는 결측치가 있는 행을 삭제하는 메서드입니다. remove_na()는 존재하지 않는 메서드입니다.",
    "code": "df_clean = df.dropna()",
    "difficulty": "easy"
  },
  {
    "id": "q161",
    "category": "범주형 인코딩",
    "question": "범주형 데이터를 원-핫 인코딩하는 pandas 함수는?",
    "options": [
      "pd.onehot()",
      "pd.get_dummies()"
    ],
    "correctAnswer": 1,
    "explanation": "pd.get_dummies()는 범주형 데이터를 원-핫 인코딩하는 pandas 함수입니다. pd.onehot()는 존재하지 않는 함수입니다.",
    "code": "df_encoded = pd.get_dummies(df, columns=['category'])",
    "difficulty": "easy"
  },
  {
    "id": "q162",
    "category": "범주형 인코딩",
    "question": "sklearn에서 원-핫 인코딩을 수행하는 클래스는?",
    "options": [
      "OneHotEncoder",
      "OneHot"
    ],
    "correctAnswer": 0,
    "explanation": "OneHotEncoder는 sklearn에서 원-핫 인코딩을 수행하는 클래스입니다. OneHot은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import OneHotEncoder",
    "difficulty": "medium"
  },
  {
    "id": "q163",
    "category": "범주형 인코딩",
    "question": "라벨 인코딩을 수행하는 sklearn 클래스는?",
    "options": [
      "Label",
      "LabelEncoder"
    ],
    "correctAnswer": 1,
    "explanation": "LabelEncoder는 라벨 인코딩을 수행하는 sklearn 클래스입니다. Label은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import LabelEncoder",
    "difficulty": "medium"
  },
  {
    "id": "q164",
    "category": "범주형 인코딩",
    "question": "OneHotEncoder에서 새로운 범주를 처리하는 파라미터는?",
    "options": [
      "handle_unknown='ignore'",
      "unknown='ignore'"
    ],
    "correctAnswer": 0,
    "explanation": "handle_unknown='ignore'는 OneHotEncoder에서 새로운 범주를 처리하는 파라미터입니다. unknown='ignore'는 존재하지 않는 파라미터입니다.",
    "code": "ohe = OneHotEncoder(handle_unknown='ignore')",
    "difficulty": "hard"
  },
  {
    "id": "q165",
    "category": "범주형 인코딩",
    "question": "get_dummies에서 첫 번째 더미 변수를 제거하는 파라미터는?",
    "options": [
      "drop_first=True",
      "remove_first=True"
    ],
    "correctAnswer": 0,
    "explanation": "drop_first=True는 get_dummies에서 첫 번째 더미 변수를 제거하는 파라미터입니다. remove_first=True는 존재하지 않는 파라미터입니다.",
    "code": "df_encoded = pd.get_dummies(df, columns=['category'], drop_first=True)",
    "difficulty": "medium"
  },
  {
    "id": "q166",
    "category": "데이터셋 분리",
    "question": "데이터를 훈련/테스트로 분리하는 sklearn 함수는?",
    "options": [
      "split_data",
      "train_test_split"
    ],
    "correctAnswer": 1,
    "explanation": "train_test_split은 데이터를 훈련/테스트로 분리하는 sklearn 함수입니다. split_data는 존재하지 않는 함수입니다.",
    "code": "from sklearn.model_selection import train_test_split",
    "difficulty": "easy"
  },
  {
    "id": "q167",
    "category": "데이터셋 분리",
    "question": "train_test_split에서 테스트셋 비율을 설정하는 파라미터는?",
    "options": [
      "test_ratio",
      "test_size"
    ],
    "correctAnswer": 1,
    "explanation": "test_size는 train_test_split에서 테스트셋 비율을 설정하는 파라미터입니다. test_ratio는 존재하지 않는 파라미터입니다.",
    "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)",
    "difficulty": "easy"
  },
  {
    "id": "q168",
    "category": "데이터셋 분리",
    "question": "train_test_split에서 재현성을 위한 파라미터는?",
    "options": [
      "random_state",
      "seed"
    ],
    "correctAnswer": 0,
    "explanation": "random_state는 train_test_split에서 재현성을 위한 파라미터입니다. seed는 존재하지 않는 파라미터입니다.",
    "code": "train_test_split(X, y, random_state=42)",
    "difficulty": "easy"
  },
  {
    "id": "q169",
    "category": "데이터셋 분리",
    "question": "클래스 비율을 유지하는 파라미터는?",
    "options": [
      "balance",
      "stratify"
    ],
    "correctAnswer": 1,
    "explanation": "stratify는 train_test_split에서 클래스 비율을 유지하는 파라미터입니다. balance는 존재하지 않는 파라미터입니다.",
    "code": "train_test_split(X, y, stratify=y)",
    "difficulty": "medium"
  },
  {
    "id": "q170",
    "category": "데이터셋 분리",
    "question": "시계열 데이터를 분리할 때 사용하는 방법은?",
    "options": [
      "랜덤 분할",
      "순차 분할"
    ],
    "correctAnswer": 1,
    "explanation": "시계열 데이터는 시간 순서를 유지해야 하므로 순차 분할을 사용해야 합니다. 랜덤 분할은 미래 정보 누수를 야기할 수 있습니다.",
    "code": "split_idx = int(len(df) * 0.8)\ntrain, test = df[:split_idx], df[split_idx:]",
    "difficulty": "medium"
  },
  {
    "id": "q171",
    "category": "스케일링",
    "question": "표준화를 수행하는 sklearn 클래스는?",
    "options": [
      "StandardScaler",
      "StandardScale"
    ],
    "correctAnswer": 0,
    "explanation": "StandardScaler는 표준화를 수행하는 sklearn 클래스입니다. StandardScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import StandardScaler",
    "difficulty": "easy"
  },
  {
    "id": "q172",
    "category": "스케일링",
    "question": "정규화를 수행하는 sklearn 클래스는?",
    "options": [
      "MinMaxScaler",
      "MinMaxScale"
    ],
    "correctAnswer": 0,
    "explanation": "MinMaxScaler는 정규화를 수행하는 sklearn 클래스입니다. MinMaxScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import MinMaxScaler",
    "difficulty": "easy"
  },
  {
    "id": "q173",
    "category": "스케일링",
    "question": "이상치에 강한 스케일링을 수행하는 sklearn 클래스는?",
    "options": [
      "RobustScale",
      "RobustScaler"
    ],
    "correctAnswer": 1,
    "explanation": "RobustScaler는 이상치에 강한 스케일링을 수행하는 sklearn 클래스입니다. RobustScale은 존재하지 않는 클래스입니다.",
    "code": "from sklearn.preprocessing import RobustScaler",
    "difficulty": "medium"
  },
  {
    "id": "q174",
    "category": "스케일링",
    "question": "스케일러를 훈련시키는 메서드는?",
    "options": [
      "fit()",
      "train()"
    ],
    "correctAnswer": 0,
    "explanation": "fit()은 스케일러를 훈련시키는 메서드입니다. train()은 존재하지 않는 메서드입니다.",
    "code": "scaler.fit(X_train)",
    "difficulty": "easy"
  },
  {
    "id": "q175",
    "category": "스케일링",
    "question": "스케일러를 적용하는 메서드는?",
    "options": [
      "transform()",
      "apply()"
    ],
    "correctAnswer": 0,
    "explanation": "transform()은 스케일러를 적용하는 메서드입니다. apply()는 존재하지 않는 메서드입니다.",
    "code": "X_scaled = scaler.transform(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q176",
    "category": "기본 모델링",
    "question": "의사결정나무 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "DecisionTree",
      "DecisionTreeClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "DecisionTreeClassifier는 의사결정나무 분류기를 생성하는 sklearn 클래스입니다. DecisionTree는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.tree import DecisionTreeClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q177",
    "category": "기본 모델링",
    "question": "로지스틱 회귀를 수행하는 sklearn 클래스는?",
    "options": [
      "LogisticReg",
      "LogisticRegression"
    ],
    "correctAnswer": 1,
    "explanation": "LogisticRegression은 로지스틱 회귀를 수행하는 sklearn 클래스입니다. LogisticReg는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.linear_model import LogisticRegression",
    "difficulty": "easy"
  },
  {
    "id": "q178",
    "category": "기본 모델링",
    "question": "K-최근접 이웃 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "KNeighbors",
      "KNeighborsClassifier"
    ],
    "correctAnswer": 1,
    "explanation": "KNeighborsClassifier는 K-최근접 이웃 분류기를 생성하는 sklearn 클래스입니다. KNeighbors는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.neighbors import KNeighborsClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q179",
    "category": "기본 모델링",
    "question": "모델을 학습시키는 메서드는?",
    "options": [
      "train()",
      "fit()"
    ],
    "correctAnswer": 1,
    "explanation": "fit()은 모델을 학습시키는 메서드입니다. train()은 존재하지 않는 메서드입니다.",
    "code": "model.fit(X_train, y_train)",
    "difficulty": "easy"
  },
  {
    "id": "q180",
    "category": "기본 모델링",
    "question": "모델로 예측을 수행하는 메서드는?",
    "options": [
      "forecast()",
      "predict()"
    ],
    "correctAnswer": 1,
    "explanation": "predict()은 모델로 예측을 수행하는 메서드입니다. forecast()는 존재하지 않는 메서드입니다.",
    "code": "y_pred = model.predict(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q181",
    "category": "앙상블 모델링",
    "question": "랜덤 포레스트 분류기를 생성하는 sklearn 클래스는?",
    "options": [
      "RandomForestClassifier",
      "RandomForest"
    ],
    "correctAnswer": 0,
    "explanation": "RandomForestClassifier는 랜덤 포레스트 분류기를 생성하는 sklearn 클래스입니다. RandomForest는 존재하지 않는 클래스입니다.",
    "code": "from sklearn.ensemble import RandomForestClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q182",
    "category": "앙상블 모델링",
    "question": "XGBoost 분류기를 생성하는 클래스는?",
    "options": [
      "XGBClassifier",
      "XGBoostClassifier"
    ],
    "correctAnswer": 0,
    "explanation": "XGBClassifier는 XGBoost 분류기를 생성하는 클래스입니다. XGBoostClassifier는 존재하지 않는 클래스입니다.",
    "code": "from xgboost import XGBClassifier",
    "difficulty": "easy"
  },
  {
    "id": "q183",
    "category": "앙상블 모델링",
    "question": "RandomForest에서 트리의 개수를 설정하는 파라미터는?",
    "options": [
      "n_estimators",
      "n_trees"
    ],
    "correctAnswer": 0,
    "explanation": "n_estimators는 RandomForest에서 트리의 개수를 설정하는 파라미터입니다. n_trees는 존재하지 않는 파라미터입니다.",
    "code": "rf = RandomForestClassifier(n_estimators=100)",
    "difficulty": "medium"
  },
  {
    "id": "q184",
    "category": "앙상블 모델링",
    "question": "XGBoost에서 학습률을 설정하는 파라미터는?",
    "options": [
      "lr",
      "learning_rate"
    ],
    "correctAnswer": 1,
    "explanation": "learning_rate는 XGBoost에서 학습률을 설정하는 파라미터입니다. lr은 존재하지 않는 파라미터입니다.",
    "code": "xgb = XGBClassifier(learning_rate=0.1)",
    "difficulty": "medium"
  },
  {
    "id": "q185",
    "category": "앙상블 모델링",
    "question": "특성 중요도를 확인하는 속성은?",
    "options": [
      "feature_importance",
      "feature_importances_"
    ],
    "correctAnswer": 1,
    "explanation": "feature_importances_는 특성 중요도를 확인하는 속성입니다. feature_importance는 존재하지 않는 속성입니다.",
    "code": "importance = rf.feature_importances_",
    "difficulty": "medium"
  },
  {
    "id": "q186",
    "category": "모델 성능 평가",
    "question": "분류 모델의 정확도를 계산하는 sklearn 함수는?",
    "options": [
      "accuracy",
      "accuracy_score"
    ],
    "correctAnswer": 1,
    "explanation": "accuracy_score는 분류 모델의 정확도를 계산하는 sklearn 함수입니다. accuracy는 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import accuracy_score",
    "difficulty": "easy"
  },
  {
    "id": "q187",
    "category": "모델 성능 평가",
    "question": "정밀도를 계산하는 sklearn 함수는?",
    "options": [
      "precision_score",
      "precision"
    ],
    "correctAnswer": 0,
    "explanation": "precision_score는 정밀도를 계산하는 sklearn 함수입니다. precision은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import precision_score",
    "difficulty": "medium"
  },
  {
    "id": "q188",
    "category": "모델 성능 평가",
    "question": "재현율을 계산하는 sklearn 함수는?",
    "options": [
      "recall",
      "recall_score"
    ],
    "correctAnswer": 1,
    "explanation": "recall_score는 재현율을 계산하는 sklearn 함수입니다. recall은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import recall_score",
    "difficulty": "medium"
  },
  {
    "id": "q189",
    "category": "모델 성능 평가",
    "question": "F1 점수를 계산하는 sklearn 함수는?",
    "options": [
      "f1",
      "f1_score"
    ],
    "correctAnswer": 1,
    "explanation": "f1_score는 F1 점수를 계산하는 sklearn 함수입니다. f1은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import f1_score",
    "difficulty": "medium"
  },
  {
    "id": "q190",
    "category": "모델 성능 평가",
    "question": "혼동행렬을 계산하는 sklearn 함수는?",
    "options": [
      "confusion",
      "confusion_matrix"
    ],
    "correctAnswer": 1,
    "explanation": "confusion_matrix는 혼동행렬을 계산하는 sklearn 함수입니다. confusion은 존재하지 않는 함수입니다.",
    "code": "from sklearn.metrics import confusion_matrix",
    "difficulty": "medium"
  },
  {
    "id": "q191",
    "category": "딥러닝 모델 구성",
    "question": "Keras Sequential 모델을 생성하는 방법은?",
    "options": [
      "keras.Model()",
      "keras.Sequential()"
    ],
    "correctAnswer": 1,
    "explanation": "keras.Sequential()은 순차적 레이어를 쌓는 모델을 생성합니다. keras.Model()은 함수형 API용입니다.",
    "code": "model = keras.Sequential()",
    "difficulty": "easy"
  },
  {
    "id": "q192",
    "category": "딥러닝 모델 구성",
    "question": "완전연결 레이어를 추가하는 Keras 클래스는?",
    "options": [
      "keras.layers.FullyConnected",
      "keras.layers.Dense"
    ],
    "correctAnswer": 1,
    "explanation": "keras.layers.Dense는 완전연결 레이어를 추가하는 Keras 클래스입니다. FullyConnected는 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Dense(64, activation='relu')",
    "difficulty": "easy"
  },
  {
    "id": "q193",
    "category": "딥러닝 모델 구성",
    "question": "드롭아웃 레이어를 추가하는 Keras 클래스는?",
    "options": [
      "keras.layers.Drop",
      "keras.layers.Dropout"
    ],
    "correctAnswer": 1,
    "explanation": "keras.layers.Dropout은 드롭아웃 레이어를 추가하는 Keras 클래스입니다. Drop은 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Dropout(0.2)",
    "difficulty": "easy"
  },
  {
    "id": "q194",
    "category": "딥러닝 모델 구성",
    "question": "입력 레이어를 정의하는 Keras 클래스는?",
    "options": [
      "keras.layers.Input",
      "keras.layers.InputLayer"
    ],
    "correctAnswer": 0,
    "explanation": "keras.layers.Input은 입력 레이어를 정의하는 Keras 클래스입니다. InputLayer는 존재하지 않는 클래스입니다.",
    "code": "keras.layers.Input(shape=(input_dim,))",
    "difficulty": "medium"
  },
  {
    "id": "q195",
    "category": "딥러닝 모델 구성",
    "question": "모델을 컴파일하는 메서드는?",
    "options": [
      "build()",
      "compile()"
    ],
    "correctAnswer": 1,
    "explanation": "compile()은 모델을 컴파일하는 메서드입니다. build()는 존재하지 않는 메서드입니다.",
    "code": "model.compile(optimizer='adam', loss='binary_crossentropy')",
    "difficulty": "easy"
  },
  {
    "id": "q196",
    "category": "딥러닝 평가 및 시각화",
    "question": "학습 과정을 시각화하는 방법은?",
    "options": [
      "plt.plot(history.history['loss'])",
      "plt.plot(history.loss)"
    ],
    "correctAnswer": 0,
    "explanation": "history.history['loss']는 학습 과정의 손실을 저장하는 딕셔너리입니다. history.loss는 존재하지 않는 속성입니다.",
    "code": "plt.plot(history.history['loss'])",
    "difficulty": "medium"
  },
  {
    "id": "q197",
    "category": "딥러닝 평가 및 시각화",
    "question": "검증 손실을 시각화하는 방법은?",
    "options": [
      "plt.plot(history.history['val_loss'])",
      "plt.plot(history.val_loss)"
    ],
    "correctAnswer": 0,
    "explanation": "history.history['val_loss']는 검증 손실을 저장하는 딕셔너리입니다. history.val_loss는 존재하지 않는 속성입니다.",
    "code": "plt.plot(history.history['val_loss'])",
    "difficulty": "medium"
  },
  {
    "id": "q198",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델을 저장하는 메서드는?",
    "options": [
      "model.store()",
      "model.save()"
    ],
    "correctAnswer": 1,
    "explanation": "model.save()는 모델을 저장하는 메서드입니다. model.store()는 존재하지 않는 메서드입니다.",
    "code": "model.save('model.keras')",
    "difficulty": "easy"
  },
  {
    "id": "q199",
    "category": "딥러닝 평가 및 시각화",
    "question": "저장된 모델을 로드하는 함수는?",
    "options": [
      "keras.models.load_model()",
      "keras.load_model()"
    ],
    "correctAnswer": 0,
    "explanation": "keras.models.load_model()은 저장된 모델을 로드하는 함수입니다. keras.load_model()은 존재하지 않는 함수입니다.",
    "code": "model = keras.models.load_model('model.keras')",
    "difficulty": "easy"
  },
  {
    "id": "q200",
    "category": "딥러닝 평가 및 시각화",
    "question": "모델로 예측을 수행하는 메서드는?",
    "options": [
      "model.predict()",
      "model.forecast()"
    ],
    "correctAnswer": 0,
    "explanation": "model.predict()는 모델로 예측을 수행하는 메서드입니다. model.forecast()는 존재하지 않는 메서드입니다.",
    "code": "y_pred = model.predict(X_test)",
    "difficulty": "easy"
  },
  {
    "id": "q201",
    "category": "데이터 불러오기",
    "question": "df.info() 실행 결과, 'Age' 컬럼이 'Non-Null Count'가 'Total'보다 적고 'Dtype'이 'float64'로 나왔습니다. 머신러닝 학습 전 'Age' 컬럼에 필요한 전처리는 무엇인가요?",
    "options": [
      "결측치 처리 (예: 평균/중앙값 대체)",
      "타입 변경 (예: int로 변경)"
    ],
    "correctAnswer": 0,
    "explanation": "Non-Null Count가 Total보다 적다는 것은 결측치(Missing Value)가 존재한다는 의미입니다. 모델 학습 전에는 결측치를 채우거나(fillna) 삭제(dropna)해야 합니다.",
    "code": "df['Age'] = df['Age'].fillna(df['Age'].median())",
    "difficulty": "medium"
  },
  {
    "id": "q202",
    "category": "모델 성능 평가",
    "question": "분류 모델의 classification_report() 결과, 'Class A'의 'recall' 값이 0.50으로 나왔습니다. 이 값은 무엇을 의미하나요?",
    "options": [
      "모델이 'Class A'로 예측한 것 중 절반만 맞았다.",
      "실제 'Class A' 데이터 중 절반만 'Class A'로 올바르게 예측했다."
    ],
    "correctAnswer": 1,
    "explanation": "재현율(Recall)은 실제 Positive 샘플 중에서 모델이 Positive로 올바르게 예측한 샘플의 비율입니다. (TP / (TP + FN))",
    "code": "print(classification_report(y_test, y_pred))",
    "difficulty": "hard"
  },
  {
    "id": "q203",
    "category": "데이터셋 분리",
    "question": "데이터의 불균형(imbalance) 문제를 해결하기 위해 train_test_split() 함수에서 사용해야 하는 파라미터는 무엇인가요?",
    "options": [
      "stratify=y",
      "balance=True"
    ],
    "correctAnswer": 0,
    "explanation": "stratify=y (타겟 변수) 옵션을 사용하면, 원본 데이터의 클래스 비율을 유지하면서 훈련셋과 테스트셋을 분할합니다.",
    "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)",
    "difficulty": "medium"
  },
  {
    "id": "q204",
    "category": "스케일링",
    "question": "테스트 데이터셋(X_test)을 스케일링할 때 scaler.fit_transform(X_test) 대신 scaler.transform(X_test)을 사용하는 주된 이유는 무엇인가요?",
    "options": [
      "데이터 누수(Data Leakage) 방지",
      "계산 속도 향상"
    ],
    "correctAnswer": 0,
    "explanation": "fit() 과정은 훈련 데이터(X_train)의 통계치(평균, 표준편차 등)를 계산하는 과정입니다. 테스트 데이터의 통계치를 사용하면 정보가 누수되어 모델 성능이 과대평가됩니다.",
    "code": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
    "difficulty": "hard"
  },
  {
    "id": "q205",
    "category": "데이터 시각화",
    "question": "상관관계 히트맵(sns.heatmap)에서 두 변수가 짙은 파란색(어두운 색)으로 표시되었습니다. 이는 무엇을 의미하나요? (단, cmap='viridis' 기준)",
    "options": [
      "강한 음의 상관관계 (-1에 가까움)",
      "강한 양의 상관관계 (+1에 가까움)"
    ],
    "correctAnswer": 0,
    "explanation": "기본 컬러맵(cmap)에서 어두운 색은 낮은 값(-1)을, 밝은 노란색은 높은 값(+1)을 의미합니다. 두 변수는 강한 음의 상관관계를 가집니다.",
    "code": "sns.heatmap(df.corr(), annot=True, cmap='viridis')",
    "difficulty": "medium"
  },
  {
    "id": "q206",
    "category": "그룹화 및 집계",
    "question": "DataFrame 'df'에서 'Category' 컬럼별로 'Sales' 컬럼의 평균을 구하는 코드입니다. 빈칸에 알맞은 메서드는?\n\ndf.____('Category')['Sales'].mean()",
    "options": [
      "groupby",
      "filter"
    ],
    "correctAnswer": 0,
    "explanation": "groupby() 메서드는 특정 컬럼을 기준으로 데이터를 그룹화하여 집계 함수(mean, sum 등)를 적용할 수 있게 합니다.",
    "code": "df.groupby('Category')['Sales'].mean()",
    "difficulty": "easy"
  },
  {
    "id": "q207",
    "category": "데이터 전처리",
    "question": "DataFrame 'df'의 'Date' 컬럼(object 타입)을 datetime 타입으로 변환하는 코드입니다. 빈칸에 알맞은 함수는?\n\ndf['Date'] = pd.____(df['Date'])",
    "options": [
      "to_datetime",
      "convert_datetime"
    ],
    "correctAnswer": 0,
    "explanation": "pandas의 to_datetime() 함수는 문자열이나 숫자로 된 날짜 데이터를 datetime 객체로 변환하는 표준 함수입니다.",
    "code": "df['Date'] = pd.to_datetime(df['Date'])",
    "difficulty": "easy"
  },
  {
    "id": "q208",
    "category": "범주형 인코딩",
    "question": "(시나리오) 'Color' 컬럼(Red, Green, Blue)을 원-핫 인코딩하려고 합니다. 다중공선성(Multicollinearity)을 방지하기 위해 첫 번째 더미 변수를 제거하는 파라미터는 무엇인가요?",
    "options": [
      "pd.get_dummies(df, columns=['Color'], drop_first=True)",
      "pd.get_dummies(df, columns=['Color'], sparse=True)"
    ],
    "correctAnswer": 0,
    "explanation": "drop_first=True 파라미터는 k개의 범주를 k-1개의 더미 변수로 변환하여, 변수 간 완벽한 선형 관계(다중공선성)가 발생하는 것을 방지합니다.",
    "code": "df_encoded = pd.get_dummies(df, columns=['Color'], drop_first=True)",
    "difficulty": "medium"
  },
  {
    "id": "q209",
    "category": "딥러닝 모델 구성",
    "question": "Keras 모델 학습 시, 검증 손실(val_loss)이 5 에포크(epoch) 동안 개선되지 않으면 학습을 조기 종료하는 콜백(Callback)은 무엇인가요?",
    "options": [
      "EarlyStopping(patience=5)",
      "ModelCheckpoint(patience=5)"
    ],
    "correctAnswer": 0,
    "explanation": "EarlyStopping 콜백은 모니터링하는 지표(기본값 'val_loss')가 'patience' 횟수만큼 개선되지 않으면 학습을 중단시켜 과적합을 방지합니다.",
    "code": "from tensorflow.keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_loss', patience=5)",
    "difficulty": "medium"
  },
  {
    "id": "q210",
    "category": "라이브러리 임포트",
    "question": "scikit-learn에서 표준화(평균 0, 분산 1)를 위해 사용하는 StandardScaler는 어느 모듈에 있나요?",
    "options": [
      "sklearn.preprocessing",
      "sklearn.model_selection"
    ],
    "correctAnswer": 0,
    "explanation": "StandardScaler, MinMaxScaler 등 데이터 스케일링 관련 도구들은 sklearn.preprocessing 모듈에 포함되어 있습니다.",
    "code": "from sklearn.preprocessing import StandardScaler",
    "difficulty": "easy"
  },
  {
    "id": "q211",
    "category": "데이터 불러오기",
    "question": "df.describe() 실행 결과, 'Age' 컬럼의 'mean' 값이 30.0이고 '50%'(중앙값) 값이 25.0일 때, 'Age' 컬럼의 데이터 분포는 어떤 형태일 가능성이 높은가요?",
    "options": [
      "오른쪽으로 꼬리가 긴 분포 (Positively Skewed)",
      "왼쪽으로 꼬리가 긴 분포 (Negatively Skewed)"
    ],
    "correctAnswer": 0,
    "explanation": "평균(mean)이 중앙값(median)보다 크면, 데이터는 오른쪽(큰 값)으로 긴 꼬리를 갖는, 즉 오른쪽으로 치우친(정적 편포) 분포일 가능성이 높습니다.",
    "code": "print(df['Age'].describe())",
    "difficulty": "medium"
  },
  {
    "id": "q212",
    "category": "데이터 불러오기",
    "question": "'data.csv' 파일의 1, 3, 5번 행을 건너뛰고(skip) 데이터를 불러오는 코드입니다. 빈칸에 알맞은 파라미터는?\n\npd.read_csv('data.csv', ____=[1, 3, 5])",
    "options": [
      "skiprows",
      "header"
    ],
    "correctAnswer": 0,
    "explanation": "skiprows 파라미터에 리스트를 전달하면 해당 인덱스(0부터 시작)의 행들을 건너뛰고 데이터를 불러옵니다.",
    "code": "df = pd.read_csv('data.csv', skiprows=[1, 3, 5])",
    "difficulty": "medium"
  },
  {
    "id": "q213",
    "category": "데이터 불러오기",
    "question": "데이터의 마지막 3행을 확인하는 Pandas 메서드는?",
    "options": [
      "df.tail(3)",
      "df.last(3)"
    ],
    "correctAnswer": 0,
    "explanation": "df.tail(n)은 데이터프레임의 마지막 n개의 행을 반환합니다. 기본값은 5입니다.",
    "code": "print(df.tail(3))",
    "difficulty": "easy"
  },
  {
    "id": "q214",
    "category": "데이터 시각화",
    "question": "Matplotlib을 사용하여 그래프의 X축 레이블을 'Age'로 설정하는 올바른 코드는?",
    "options": [
      "plt.xlabel('Age')",
      "plt.xlabel = 'Age'"
    ],
    "correctAnswer": 0,
    "explanation": "Matplotlib에서는 plt.xlabel(), plt.ylabel(), plt.title() 등의 함수를 사용하여 그래프의 구성 요소를 설정합니다.",
    "code": "import matplotlib.pyplot as plt\nplt.plot(data)\nplt.xlabel('Age')",
    "difficulty": "easy"
  },
  {
    "id": "q215",
    "category": "데이터 시각화",
    "question": "Seaborn의 sns.pairplot(df) 함수를 사용하는 주된 목적은 무엇인가요?",
    "options": [
      "데이터프레임의 모든 수치형 변수 간의 쌍별(pairwise) 관계와 분포를 한 번에 확인하기 위해",
      "특정 두 변수 간의 상관관계만 집중적으로 확인하기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "pairplot은 그리드(grid) 형태로 각 수치형 변수 쌍의 산점도(scatterplot)를, 대각선에는 해당 변수의 분포(히스토그램 또는 kde)를 그려줍니다.",
    "code": "import seaborn as sns\nsns.pairplot(df)",
    "difficulty": "medium"
  },
  {
    "id": "q216",
    "category": "데이터 시각화",
    "question": "sns.boxplot() 실행 결과, 박스(box)의 범위를 벗어난 위치에 여러 개의 점(point)이 찍혀있습니다. 이 점들은 통계적으로 무엇을 의미하나요?",
    "options": [
      "이상치 (Outliers)",
      "평균 (Mean)"
    ],
    "correctAnswer": 0,
    "explanation": "박스플롯에서 점(flier)으로 표시되는 데이터 포인트는 IQR(사분위수 범위)의 1.5배를 벗어난 값들로, 일반적으로 이상치로 간주됩니다.",
    "code": "sns.boxplot(data=df, y='Age')",
    "difficulty": "easy"
  },
  {
    "id": "q217",
    "category": "데이터 시각화",
    "question": "sns.countplot()으로 그린 그래프를 'plot.png' 파일로 저장하는 코드입니다. 빈칸에 알맞은 함수는?\n\nsns.countplot(data=df, x='col')\nplt.____('plot.png')",
    "options": [
      "savefig",
      "saveplot"
    ],
    "correctAnswer": 0,
    "explanation": "Seaborn은 Matplotlib을 기반으로 하므로, 그래프를 저장할 때는 Matplotlib의 plt.savefig() 함수를 사용합니다.",
    "code": "import matplotlib.pyplot as plt\nplt.savefig('plot.png')",
    "difficulty": "easy"
  },
  {
    "id": "q218",
    "category": "그룹화 및 집계",
    "question": "(시나리오) 'Category'별로 'Sales'의 평균(mean)과 'Profit'의 합계(sum)를 동시에 계산하는 올바른 코드는?",
    "options": [
      "df.groupby('Category').agg({'Sales':'mean', 'Profit':'sum'})",
      "df.groupby('Category').apply({'Sales':'mean', 'Profit':'sum'})"
    ],
    "correctAnswer": 0,
    "explanation": "agg() (또는 aggregate()) 메서드를 사용하면 딕셔너리 형태로 각 컬럼에 적용할 집계 함수를 유연하게 지정할 수 있습니다.",
    "code": "result = df.groupby('Category').agg({'Sales':'mean', 'Profit':'sum'})",
    "difficulty": "hard"
  },
  {
    "id": "q219",
    "category": "그룹화 및 집계",
    "question": "그룹화 연산 시, df.groupby('Group')['Value'].transform(lambda x: ...)`은 원본 DataFrame과 동일한 인덱스(길이)를 반환합니다. 이 `transform`의 주된 용도는 무엇인가요?",
    "options": [
      "그룹별 통계치(평균, 합계 등)를 원본 데이터의 모든 행에 매핑하기 위해",
      "그룹별로 단일 요약 통계치를 생성하기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "transform은 그룹별 계산 결과를 원래 DataFrame의 인덱스에 맞춰 반환합니다. (예: 그룹 평균으로 결측치 채우기, 그룹 내 비율 계산)",
    "code": "df['Group_Mean'] = df.groupby('Group')['Value'].transform('mean')",
    "difficulty": "hard"
  },
  {
    "id": "q220",
    "category": "그룹화 및 집계",
    "question": "df['Category'] 컬럼의 고유값(unique value)별 개수를 세는 코드입니다. 빈칸에 알맞은 메서드는?\n\ndf['Category'].____()",
    "options": [
      "value_counts",
      "unique_counts"
    ],
    "correctAnswer": 0,
    "explanation": "value_counts()는 Pandas Series에서 고유값의 빈도를 계산하는 데 사용되는 핵심 메서드입니다.",
    "code": "print(df['Category'].value_counts())",
    "difficulty": "easy"
  },
  {
    "id": "q221",
    "category": "그룹화 및 집계",
    "question": "DataFrame `df`의 모든 수치형 컬럼에 대해 평균, 중앙값, 개수를 한 번에 계산하는 메서드는?",
    "options": [
      "df.describe()",
      "df.info()"
    ],
    "correctAnswer": 0,
    "explanation": "df.describe()는 수치형 데이터의 기술 통계량(개수, 평균, 표준편차, 최소값, 4분위수, 최대값)을 요약하여 보여줍니다.",
    "code": "print(df.describe())",
    "difficulty": "easy"
  },
  {
    "id": "q222",
    "category": "데이터 전처리",
    "question": "(시나리오) 'Name' 컬럼에 \"Kim, Yuna\"처럼 성과 이름이 쉼표(,)로 구분되어 있습니다. 쉼표를 기준으로 분리하여 'Kim'만 가져오는 올바른 코드는?",
    "options": [
      "df['Name'].str.split(',').str[0]",
      "df['Name'].split(',')[0]"
    ],
    "correctAnswer": 0,
    "explanation": "Pandas Series의 문자열 처리를 위해서는 `.str` 접근자를 사용해야 합니다. `.str.split()`은 리스트를 반환하며, `.str[0]`으로 첫 번째 요소에 접근할 수 있습니다.",
    "code": "df['Last_Name'] = df['Name'].str.split(',').str[0]",
    "difficulty": "medium"
  },
  {
    "id": "q223",
    "category": "데이터 전처리",
    "question": "'Price' 컬럼의 값이 '1,000'처럼 문자열(object)일 때, 쉼표(,)를 제거하는 코드입니다. 빈칸에 알맞은 메서드는?\n\ndf['Price'].str.____(',', '')",
    "options": [
      "replace",
      "remove"
    ],
    "correctAnswer": 0,
    "explanation": "Pandas Series의 문자열을 치환할 때는 `.str.replace()` 메서드를 사용합니다.",
    "code": "df['Price'] = df['Price'].str.replace(',', '')",
    "difficulty": "easy"
  },
  {
    "id": "q224",
    "category": "데이터 전처리",
    "question": "'Price' 컬럼(object 타입)을 숫자형(int)으로 바꾸는 코드입니다. 빈칸에 알맞은 메서드는?\n\ndf['Price'] = df['Price'].____(int)",
    "options": [
      "astype",
      "to_type"
    ],
    "correctAnswer": 0,
    "explanation": "astype() 메서드는 Pandas Series 또는 DataFrame의 데이터 타입을 변경하는 데 사용됩니다.",
    "code": "df['Price'] = df['Price'].astype(int)",
    "difficulty": "easy"
  },
  {
    "id": "q225",
    "category": "데이터 전처리",
    "question": "'UserID'나 'Row_ID'처럼 행을 식별하는 고유 ID 컬럼을 모델 학습 전에 제거해야 하는 주된 이유는 무엇인가요?",
    "options": [
      "모델이 ID 자체를 유의미한 패턴으로 오해하여 과적합(Overfitting)을 유발할 수 있기 때문",
      "ID 컬럼은 항상 결측치를 포함하기 때문"
    ],
    "correctAnswer": 0,
    "explanation": "고유 ID 컬럼은 타겟 변수와 아무런 인과 관계가 없지만, 모델이 우연한 패턴을 학습하여 성능이 왜곡될 수 있습니다. (예: ID가 높을수록 긍정적이라 오해)",
    "code": "df = df.drop(columns=['UserID', 'Row_ID'])",
    "difficulty": "medium"
  },
  {
    "id": "q226",
    "category": "데이터 전처리",
    "question": "DataFrame `df`에서 'col1'과 'col2' 두 개의 컬럼을 삭제(drop)하는 올바른 코드는?",
    "options": [
      "df.drop(columns=['col1', 'col2'])",
      "df.drop(['col1', 'col2'], axis=0)"
    ],
    "correctAnswer": 0,
    "explanation": "컬럼을 삭제할 때는 `columns` 파라미터에 리스트를 명시하거나 `axis=1`을 설정해야 합니다. `axis=0`은 행(row)을 삭제합니다.",
    "code": "df_new = df.drop(columns=['col1', 'col2'])",
    "difficulty": "easy"
  },
  {
    "id": "q227",
    "category": "결측치 처리",
    "question": "결측치가 *하나라도 있는* '컬럼' 자체를 삭제하는 코드는?",
    "options": [
      "df.dropna(axis=1)",
      "df.dropna(axis=0)"
    ],
    "correctAnswer": 0,
    "explanation": "dropna() 메서드에서 `axis=1`은 컬럼을 대상으로, `axis=0`(기본값)은 행을 대상으로 작동합니다.",
    "code": "df_clean_cols = df.dropna(axis=1)",
    "difficulty": "medium"
  },
  {
    "id": "q228",
    "category": "결측치 처리",
    "question": "`df.dropna(thresh=5)` 코드는 어떤 '행'을 삭제하는가?",
    "options": [
      "결측치가 아닌(Non-NA) 유효한 값의 개수가 5개 미만인 행",
      "결측치(NA)가 5개 이상인 행"
    ],
    "correctAnswer": 0,
    "explanation": "thresh 파라미터는 '이만큼의 유효한 값이 없으면 삭제하라'는 임계값입니다. 즉, 유효한 값이 5개 미만(4개 이하)인 행이 삭제됩니다.",
    "code": "df_thresh = df.dropna(thresh=5)",
    "difficulty": "hard"
  },
  {
    "id": "q229",
    "category": "결측치 처리",
    "question": "(시나리오) 주식 가격과 같은 시계열 데이터의 결측치를 처리할 때, `fillna(df.mean())` (평균) 대신 `fillna(method='ffill')` (앞의 값)을 사용하는 주된 이유는?",
    "options": [
      "데이터의 시간적 연속성(Temporal Continuity)을 반영하기 위해",
      "평균보다 계산이 빠르기 때문에"
    ],
    "correctAnswer": 0,
    "explanation": "시계열 데이터는 시간 순서가 중요합니다. 'ffill' (forward fill)은 직전 시점의 값으로 결측치를 채워, 데이터의 연속성을 가정합니다. 평균값은 이러한 순서를 무시합니다.",
    "code": "df['Price'] = df['Price'].fillna(method='ffill')",
    "difficulty": "hard"
  },
  {
    "id": "q230",
    "category": "범주형 인코딩",
    "question": "(시나리오) '학력' 컬럼('고졸', '대졸', '석사')처럼 순서(Ordinality)가 있는 범주형 데이터에 `LabelEncoder`를 사용하는 주된 이유는?",
    "options": [
      "'고졸':0, '대졸':1, '석사':2 처럼 순서 정보를 숫자 크기에 반영할 수 있기 때문",
      "원-핫 인코딩보다 메모리를 덜 사용하기 때문"
    ],
    "correctAnswer": 0,
    "explanation": "LabelEncoder는 범주를 숫자로 변환합니다. '색상'처럼 순서가 없는 데이터에는 부적절하지만, '등급'이나 '학력'처럼 순서가 명확한 데이터에는 유용할 수 있습니다.",
    "code": "from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()",
    "difficulty": "medium"
  },
  {
    "id": "q231",
    "category": "범주형 인코딩",
    "question": "'색상' 컬럼('Red':0, 'Green':1, 'Blue':2)처럼 순서가 없는 명목형(Nominal) 데이터에 `LabelEncoder`를 사용하면 안 되는 주된 이유는?",
    "options": [
      "모델이 숫자(0, 1, 2)를 크기나 순서(예: Blue > Green)로 잘못 오해할 수 있기 때문",
      "변환 속도가 매우 느리기 때문"
    ],
    "correctAnswer": 0,
    "explanation": "선형 모델 등은 0, 1, 2라는 숫자를 순서나 크기로 해석하여 'Blue가 Green보다 2배 중요하다'처럼 잘못된 패턴을 학습할 수 있습니다. 이 경우 원-핫 인코딩이 적합합니다.",
    "code": "# Bad Practice for Nominal Data\n# df['Color_Encoded'] = LabelEncoder().fit_transform(df['Color'])",
    "difficulty": "hard"
  },
  {
    "id": "q232",
    "category": "범주형 인코딩",
    "question": "`OneHotEncoder` 사용 시, 테스트 데이터에 훈련 데이터에 없던 새로운 범주가 나타날 때 에러 대신 무시(모두 0으로 처리)하는 파라미터는?\n\nOneHotEncoder(____='ignore')",
    "options": [
      "handle_unknown",
      "new_category"
    ],
    "correctAnswer": 0,
    "explanation": "handle_unknown='ignore' 파라미터는 훈련 시 보지 못했던 새로운 범주가 transform 시점에 들어올 경우, 해당 범주를 무시하고 모든 더미 변수를 0으로 채웁니다.",
    "code": "from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown='ignore')",
    "difficulty": "medium"
  },
  {
    "id": "q233",
    "category": "데이터셋 분리",
    "question": "`train_test_split` 함수에서 `random_state=42`처럼 특정 숫자를 부여하는 주된 이유는 무엇인가요?",
    "options": [
      "실험 결과를 동일하게 재현(Reproducibility)하기 위해",
      "데이터를 더욱 무작위로 섞기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "random_state는 난수 생성의 시드(seed) 역할을 합니다. 이 값을 고정하면, 코드를 여러 번 실행해도 항상 동일한 방식으로 데이터가 분할됩니다.",
    "code": "train_test_split(X, y, test_size=0.2, random_state=42)",
    "difficulty": "easy"
  },
  {
    "id": "q234",
    "category": "데이터셋 분리",
    "question": "(시나리오) 시계열 데이터를 `train_test_split`으로 분할할 때 `shuffle=False`로 설정해야 하는 주된 이유는?",
    "options": [
      "데이터의 시간 순서를 유지하여 미래의 정보가 과거를 예측하는 것을 막기 위해 (Data Leakage 방지)",
      "데이터 셔플링에 걸리는 시간을 단축하기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "시계열 데이터는 시간 순서가 중요합니다. 데이터를 섞으면(shuffle=True) 미래의 데이터가 훈련셋에 포함되어, 모델 성능이 비현실적으로 높게 평가됩니다.",
    "code": "train_test_split(X, y, test_size=0.2, shuffle=False)",
    "difficulty": "medium"
  },
  {
    "id": "q235",
    "category": "스케일링",
    "question": "`StandardScaler` (표준화) 대신 `RobustScaler`를 사용하는 것이 더 유리한 데이터의 특징은 무엇인가요?",
    "options": [
      "데이터에 이상치(Outlier)가 많을 때",
      "데이터가 완벽한 정규분포를 따를 때"
    ],
    "correctAnswer": 0,
    "explanation": "RobustScaler는 평균/표준편차 대신 중앙값/사분위수(IQR)를 사용합니다. 이는 이상치의 영향을 덜 받기 때문에 이상치가 많은 데이터에 더 적합합니다.",
    "code": "from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()",
    "difficulty": "medium"
  },
  {
    "id": "q236",
    "category": "스케일링",
    "question": "`MinMaxScaler` (정규화)를 사용했을 때, 스케일링된 값은 기본적으로 어떤 범위를 가지나요?",
    "options": [
      "0 ~ 1",
      "-1 ~ 1"
    ],
    "correctAnswer": 0,
    "explanation": "MinMaxScaler는 모든 특성의 값을 0(최소값)과 1(최대값) 사이의 범위로 비례하게 조정합니다.",
    "code": "from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()",
    "difficulty": "easy"
  },
  {
    "id": "q237",
    "category": "스케일링",
    "question": "의사결정나무(Decision Tree)나 랜덤포레스트(RandomForest) 모델은 스케일링이 필수적이지 않은 이유는 무엇인가요?",
    "options": [
      "변수의 스케일(크기)이 아닌 분기점(split point)을 기준으로 작동하기 때문",
      "모델 내부적으로 자동 스케일링을 수행하기 때문"
    ],
    "correctAnswer": 0,
    "explanation": "트리 기반 모델은 'Age > 30'처럼 특정 값을 기준으로 데이터를 나눕니다. 'Age'가 0~1 사이든 0~100 사이든 분기점만 달라질 뿐 모델 성능에 큰 영향을 주지 않습니다.",
    "code": "# 스케일링이 필수적이지 않음\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()",
    "difficulty": "hard"
  },
  {
    "id": "q238",
    "category": "기본 모델링",
    "question": "`KNeighborsClassifier`에서 참고할 이웃의 수(K)를 5로 설정하는 파라미터는?\n\nKNeighborsClassifier(____=5)",
    "options": [
      "n_neighbors",
      "k_value"
    ],
    "correctAnswer": 0,
    "explanation": "n_neighbors 파라미터는 K-최근접 이웃 알고리즘에서 K값, 즉 몇 개의 이웃을 참고할지 결정하는 핵심 하이퍼파라미터입니다.",
    "code": "from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)",
    "difficulty": "easy"
  },
  {
    "id": "q239",
    "category": "기본 모델링",
    "question": "(시나리오) `LogisticRegression(C=0.1)` 모델을 `C=10`으로 변경했습니다. 'C' 파라미터 값이 커지면 규제(Regularization)의 강도는 어떻게 되나요?",
    "options": [
      "규제가 약해진다 (모델이 더 복잡해짐)",
      "규제가 강해진다 (모델이 더 단순해짐)"
    ],
    "correctAnswer": 0,
    "explanation": "C는 규제 강도의 역수입니다. C 값이 크면(C=10) 규제가 약해져 훈련 데이터에 더 적합(overfit)하려 하고, C 값이 작으면(C=0.1) 규제가 강해집니다.",
    "code": "# 약한 규제 (C가 큼)\nmodel = LogisticRegression(C=10)\n# 강한 규제 (C가 작음)\nmodel = LogisticRegression(C=0.1)",
    "difficulty": "hard"
  },
  {
    "id": "q240",
    "category": "기본 모델링",
    "question": "`DecisionTreeClassifier`에서 `max_depth=3` 파라미터를 설정하는 주된 목적은 무엇인가요?",
    "options": [
      "모델의 과적합(Overfitting)을 방지하고 일반화 성능을 높이기 위해",
      "모델의 훈련 속도를 높이기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "max_depth는 트리의 최대 깊이를 제한합니다. 이 값을 적절히 설정하면 트리가 너무 복잡해져 훈련 데이터에만 과적합되는 것을 막을 수 있습니다.",
    "code": "from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(max_depth=3)",
    "difficulty": "medium"
  },
  {
    "id": "q241",
    "category": "앙상블 모델링",
    "question": "랜덤포레스트(RandomForest)는 여러 개의 의사결정나무를 어떻게 결합하는 방식인가요?",
    "options": [
      "배깅(Bagging): 데이터를 샘플링하여 병렬로 학습시킨 후 결과를 투표(Voting)함",
      "부스팅(Boosting): 순차적으로 학습하며 이전 트리의 오차에 가중치를 부여함"
    ],
    "correctAnswer": 0,
    "explanation": "랜덤포레스트는 대표적인 배깅(Bootstrap Aggregating) 앙상블 기법입니다. 여러 개의 독립적인 모델을 병렬로 학습시켜 예측을 종합합니다.",
    "code": "from sklearn.ensemble import RandomForestClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q242",
    "category": "앙상블 모델링",
    "question": "XGBoost, LightGBM과 같은 모델이 '부스팅(Boosting)' 계열로 불리는 주된 이유는?",
    "options": [
      "이전 모델(트리)의 오차(Residual)를 보완하는 방식으로 순차적으로 학습하기 때문",
      "여러 모델을 독립적으로 만든 후 무작위로 결합하기 때문"
    ],
    "correctAnswer": 0,
    "explanation": "부스팅 모델은 약한 학습기(weak learner)를 순차적으로 학습시키며, 이전 단계에서 잘못 예측한 데이터에 가중치를 부여하여 점차 성능을 향상시킵니다.",
    "code": "from xgboost import XGBClassifier",
    "difficulty": "medium"
  },
  {
    "id": "q243",
    "category": "앙상블 모델링",
    "question": "`RandomForestClassifier`에서 생성할 의사결정나무의 개수를 200개로 설정하는 파라미터는?\n\nRandomForestClassifier(____=200)",
    "options": [
      "n_estimators",
      "n_trees"
    ],
    "correctAnswer": 0,
    "explanation": "n_estimators는 앙상블 모델에서 사용할 기본 모델(트리)의 개수를 지정하는 하이퍼파라미터입니다.",
    "code": "from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=200)",
    "difficulty": "easy"
  },
  {
    "id": "q244",
    "category": "모델 성능 평가",
    "question": "(시나리오) 이진 분류 모델 평가 시, 데이터가 불균형(imbalanced)할 때 정확도(Accuracy)보다 모델의 종합적인 변별력을 더 잘 나타내는 지표는? (1에 가까울수록 좋음)",
    "options": [
      "ROC AUC Score",
      "Confusion Matrix"
    ],
    "correctAnswer": 0,
    "explanation": "불균형 데이터에서는 다수 클래스만 예측해도 정확도가 높게 나옵니다. ROC AUC는 모델이 Positive와 Negative를 얼마나 잘 구별하는지(변별력)를 종합적으로 평가합니다.",
    "code": "from sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, y_pred_proba)",
    "difficulty": "medium"
  },
  {
    "id": "q245",
    "category": "모델 성능 평가",
    "question": "혼동행렬(Confusion Matrix)에서 실제는 'Positive'인데 모델이 'Negative'로 잘못 예측한 것을 무엇이라고 하는가?",
    "options": [
      "FN (False Negative, 2종 오류)",
      "FP (False Positive, 1종 오류)"
    ],
    "correctAnswer": 0,
    "explanation": "FN (False Negative)는 '틀리게(False) Negative로 예측했다'는 의미이며, 실제로는 Positive였습니다. (예: 실제 환자를 정상으로 오진)",
    "code": "from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)",
    "difficulty": "medium"
  },
  {
    "id": "q246",
    "category": "모델 성능 평가",
    "question": "회귀 모델 평가 시, `MSE` (Mean Squared Error) 대신 `RMSE` (Root Mean Squared Error)를 사용하는 주된 이유는 무엇인가요?",
    "options": [
      "오차를 실제 타겟 변수와 동일한 스케일(단위)로 해석하기 위해",
      "오차가 큰 값에 대한 패널티를 줄이기 위해"
    ],
    "correctAnswer": 0,
    "explanation": "MSE는 오차를 제곱하기 때문에 단위가 달라집니다 (예: '원' -> '원^2'). RMSE는 여기에 제곱근을 씌워 다시 '원' 단위로 만들어 오차를 직관적으로 해석할 수 있게 합니다.",
    "code": "from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)",
    "difficulty": "hard"
  },
  {
    "id": "q247",
    "category": "모델 성능 평가",
    "question": "회귀 모델의 MAE (Mean Absolute Error)를 계산하는 함수를 임포트하는 코드입니다. 빈칸에 알맞은 함수명은?\n\nfrom sklearn.metrics import ____",
    "options": [
      "mean_absolute_error",
      "mae_score"
    ],
    "correctAnswer": 0,
    "explanation": "scikit-learn의 metrics 모듈은 평가 지표 함수를 'mean_squared_error', 'mean_absolute_error' 등 풀네임으로 제공합니다.",
    "code": "from sklearn.metrics import mean_absolute_error",
    "difficulty": "easy"
  },
  {
    "id": "q248",
    "category": "딥러닝 모델 구성",
    "question": "(시나리오) 3개 이상의 클래스(예: 개, 고양이, 새)를 분류하는 딥러닝 모델의 마지막 출력 레이어(Dense)에 사용해야 하는 활성화 함수(activation)는?",
    "options": [
      "softmax",
      "sigmoid"
    ],
    "correctAnswer": 0,
    "explanation": "softmax 함수는 다중 클래스 분류에서 각 클래스에 속할 확률을 계산하며, 모든 확률의 합이 1이 되도록 합니다. sigmoid는 이진 분류(0 또는 1)에 사용됩니다.",
    "code": "model.add(keras.layers.Dense(3, activation='softmax'))",
    "difficulty": "medium"
  },
  {
    "id": "q249",
    "category": "딥러닝 평가 및 시각화",
    "question": "Keras의 `model.summary()`를 실행했을 때 출력되는 'Total params'가 의미하는 것은 무엇인가요?",
    "options": [
      "모델이 학습 과정에서 업데이트해야 할 총 가중치(Weight)와 편향(Bias)의 개수",
      "모델이 학습하는 데 사용된 총 데이터 샘플의 개수"
    ],
    "correctAnswer": 0,
    "explanation": "Total parameters는 모델의 복잡도를 나타내는 지표로, 이 파라미터들이 훈련 데이터를 통해 학습(업데이트)됩니다.",
    "code": "model.summary()",
    "difficulty": "medium"
  },
  {
    "id": "q250",
    "category": "딥러닝 모델 구성",
    "question": "Keras 모델 컴파일 시, 이진 분류(binary classification) 문제에서 일반적으로 사용되는 손실 함수(loss)는?\n\nmodel.compile(optimizer='adam', loss='____')",
    "options": [
      "binary_crossentropy",
      "categorical_crossentropy"
    ],
    "correctAnswer": 0,
    "explanation": "이진 분류(0 또는 1)에는 'binary_crossentropy'를, 3개 이상의 클래스를 분류(예: one-hot 인코딩된 타겟)할 때는 'categorical_crossentropy'를 사용합니다.",
    "code": "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])",
    "difficulty": "easy"
  },
  {
    "id": "q251",
      "category": "라이브러리 임포트",
      "question": "Python에서 현재 작업 중인 디렉토리(Current Working Directory)를 확인하는 코드는?\n\nimport os\nprint(os.____())",
      "options": [
        "getcwd",
        "pwd"
      ],
      "correctAnswer": 0,
      "explanation": "os 라이브러리의 getcwd() 함수는 'Get Current Working Directory'의 약자로, 현재 스크립트가 실행되는 위치의 경로를 반환합니다.",
      "code": "import os\nprint(os.getcwd())",
      "difficulty": "easy"
    },
    {
      "id": "q252",
      "category": "데이터 불러오기",
      "question": "(시나리오) 'data.csv' 파일의 3번째 행(row)을 헤더(header)로 사용하고 싶습니다. (0부터 시작하는 인덱스 기준) 올바른 파라미터는?",
      "options": [
        "pd.read_csv('data.csv', header=2)",
        "pd.read_csv('data.csv', header=3)"
      ],
      "correctAnswer": 0,
      "explanation": "header 파라미터는 0부터 시작하는 인덱스를 받습니다. 따라서 3번째 행을 헤더로 사용하려면 header=2로 설정해야 합니다.",
      "code": "df = pd.read_csv('data.csv', header=2)",
      "difficulty": "medium"
    },
    {
      "id": "q253",
      "category": "데이터 불러오기",
      "question": "df.info() 결과, 'Memory Usage'가 매우 크게 나왔습니다. 'Category' 컬럼(고유값 10개)의 메모리를 줄이기 위한 가장 효율적인 타입 변경은?",
      "options": [
        "df['Category'].astype('category')",
        "df['Category'].astype('str')"
      ],
      "correctAnswer": 0,
      "explanation": "object(str) 타입은 고유값이 적더라도 모든 문자열을 메모리에 저장합니다. 'category' 타입은 고유값을 정수(int)로 매핑하여 저장하므로 메모리를 획기적으로 줄일 수 있습니다.",
      "code": "df['Category'] = df['Category'].astype('category')",
      "difficulty": "medium"
    },
    {
      "id": "q254",
      "category": "데이터 시각화",
      "question": "데이터의 분포를 히스토그램(histogram)과 커널 밀도 추정(KDE) 그래프로 동시에 보여주는 seaborn 함수는?",
      "options": [
        "sns.histplot(kde=True)",
        "sns.boxplot(kde=True)"
      ],
      "correctAnswer": 0,
      "explanation": "sns.histplot() 함수에 kde=True 파라미터를 추가하면, 막대 그래프 형태의 히스토그램 위에 부드러운 곡선의 KDE 그래프를 함께 그려줍니다.",
      "code": "sns.histplot(data=df, x='Age', kde=True)",
      "difficulty": "easy"
    },
    {
      "id": "q255",
      "category": "데이터 시각화",
      "question": "sns.countplot()에서 X축의 범주(category) 순서를 'Low', 'Mid', 'High' 순으로 지정하고 싶을 때 사용하는 파라미터는?",
      "options": [
        "order=['Low', 'Mid', 'High']",
        "sort_by=['Low', 'Mid', 'High']"
      ],
      "correctAnswer": 0,
      "explanation": "order 파라미터에 원하는 순서의 리스트를 전달하면, 그래프의 X축(또는 Y축) 범주 순서를 강제로 지정할 수 있습니다.",
      "code": "sns.countplot(data=df, x='Grade', order=['Low', 'Mid', 'High'])",
      "difficulty": "medium"
    },
    {
      "id": "q256",
      "category": "데이터 시각화",
      "question": "(시나리오) Matplotlib으로 2x2 (총 4개)의 서브플롯(subplot)을 생성하고, 그중 첫 번째(좌상단) 플롯에 접근하는 올바른 코드는?",
      "options": [
        "fig, axes = plt.subplots(2, 2)\naxes[0, 0].plot(data)",
        "fig, axes = plt.subplots(2, 2)\naxes[0].plot(data)"
      ],
      "correctAnswer": 0,
      "explanation": "plt.subplots(nrows, ncols)는 figure 객체와 axes 배열을 반환합니다. 2x2일 경우, axes는 2차원 배열이 되므로 axes[행, 열] (예: axes[0, 0])로 각 플롯에 접근합니다.",
      "code": "fig, axes = plt.subplots(2, 2)\naxes[0, 0].set_title('First Plot')",
      "difficulty": "medium"
    },
    {
      "id": "q257",
      "category": "데이터 시각화",
      "question": "범주형 변수('Category')에 따른 수치형 변수('Value')의 분포를 확인할 때, 박스플롯(Boxplot)과 KDE를 결합한 형태의 그래프는?",
      "options": [
        "sns.violinplot()",
        "sns.jointplot()"
      ],
      "correctAnswer": 0,
      "explanation": "바이올린플롯(Violinplot)은 박스플롯의 통계 정보(중앙값, 사분위수)와 커널 밀도(KDE) 그래프의 분포 형태를 동시에 보여줍니다.",
      "code": "sns.violinplot(data=df, x='Category', y='Value')",
      "difficulty": "easy"
    },
    {
      "id": "q258",
      "category": "그룹화 및 집계",
      "question": "df.groupby('Category').size()와 df.groupby('Category')['Value'].count()의 결정적인 차이점은 무엇인가요?",
      "options": [
        ".size()는 결측치(NaN)를 포함하여 개수를 세고, .count()는 결측치를 제외하고 셉니다.",
        ".size()는 결측치를 제외하고 세고, .count()는 결측치를 포함하여 셉니다."
      ],
      "correctAnswer": 0,
      "explanation": ".size()는 그룹에 속한 '행의 개수' 자체를 세므로 결측치 여부와 관계없습니다. .count()는 특정 컬럼의 '값이 있는' 셀의 개수를 세므로 결측치를 제외합니다.",
      "code": "# size()는 NaN 포함, count()는 NaN 제외\ngrouped_size = df.groupby('Category').size()\ngrouped_count = df.groupby('Category')['Value'].count()",
      "difficulty": "hard"
    },
    {
      "id": "q259",
      "category": "그룹화 및 집계",
      "question": "(시나리오) 'Store'별 'Sales'의 합계를 구해 'Total_Sales'라는 컬럼명으로 변경하고, 인덱스를 리셋하는 코드입니다. 빈칸에 알맞은 파라미터는?\n\ndf.groupby('Store')['Sales'].sum().reset_index(____='Total_Sales')",
      "options": [
        "name",
        "rename"
      ],
      "correctAnswer": 0,
      "explanation": "Series (df.groupby(...).sum()의 결과)에 .reset_index()를 적용할 때 name 파라미터를 사용하면, 데이터가 된 컬럼의 이름을 지정할 수 있습니다.",
      "code": "sales_summary = df.groupby('Store')['Sales'].sum().reset_index(name='Total_Sales')",
      "difficulty": "medium"
    },
    {
      "id": "q260",
      "category": "그룹화 및 집계",
      "question": "DataFrame `df`의 인덱스(index)를 'UserID' 컬럼으로 설정하는 메서드는?",
      "options": [
        "df.set_index('UserID')",
        "df.index('UserID')"
      ],
      "correctAnswer": 0,
      "explanation": "set_index() 메서드는 기존 컬럼 중 하나를 DataFrame의 인덱스로 지정합니다.",
      "code": "df_indexed = df.set_index('UserID')",
      "difficulty": "easy"
    },
    {
      "id": "q261",
      "category": "데이터 전처리",
      "question": "DataFrame `df`의 컬럼명('Old_Name')을 'New_Name'으로 변경하는 코드입니다. 빈칸에 알맞은 파라미터는?\n\ndf.____(columns={'Old_Name': 'New_Name'})",
      "options": [
        "rename",
        "changename"
      ],
      "correctAnswer": 0,
      "explanation": "rename() 메서드는 딕셔너리 형식을 사용하여 특정 컬럼명이나 인덱스명을 변경할 수 있게 합니다.",
      "code": "df = df.rename(columns={'Old_Name': 'New_Name'})",
      "difficulty": "easy"
    },
    {
      "id": "q262",
      "category": "데이터 전처리",
      "question": "(시나리오) 'Phone' 컬럼에 '010-1234-5678' 형식의 데이터가 있습니다. 정규표현식(regex)을 사용하여 '-'를 모두 제거하는 올바른 코드는?",
      "options": [
        "df['Phone'].str.replace('-', '', regex=True)",
        "df['Phone'].str.remove('-', regex=True)"
      ],
      "correctAnswer": 0,
      "explanation": ".str.replace()는 문자열을 치환하는 함수입니다. '-'와 같은 특수 문자를 패턴으로 사용하려면 regex=True (기본값) 또는 '\\-'로 이스케이프해야 합니다.",
      "code": "df['Phone'] = df['Phone'].str.replace('-', '', regex=True)",
      "difficulty": "medium"
    },
    {
      "id": "q263",
      "category": "데이터 전처리",
      "question": "'Date' 컬럼(datetime 타입)에서 '월'(Month) 이름을 (예: 'January', 'February') 가져오는 속성은?",
      "options": [
        "df['Date'].dt.month_name()",
        "df['Date'].dt.month"
      ],
      "correctAnswer": 0,
      "explanation": ".dt.month_name()은 월 이름을 문자열로 반환하는 메서드입니다. 반면 .dt.month는 월을 숫자(1, 2, 3...)로 반환하는 속성입니다.",
      "code": "df['Month_Name'] = df['Date'].dt.month_name()",
      "difficulty": "medium"
    },
    {
      "id": "q264",
      "category": "데이터 전처리",
      "question": "DataFrame `df1`과 `df2`를 'UserID' 컬럼을 기준으로 'Inner Join'하는 Pandas 함수는?",
      "options": [
        "pd.merge(df1, df2, on='UserID', how='inner')",
        "pd.concat([df1, df2], on='UserID', how='inner')"
      ],
      "correctAnswer": 0,
      "explanation": "pd.merge()는 SQL의 JOIN과 유사하게 특정 키(key)를 기준으로 두 DataFrame을 병합합니다. pd.concat()은 데이터를 위아래나 좌우로 단순 연결(붙이기)합니다.",
      "code": "merged_df = pd.merge(df1, df2, on='UserID', how='inner')",
      "difficulty": "medium"
    },
    {
      "id": "q265",
      "category": "데이터 전처리",
      "question": "DataFrame `df1`과 `df2`를 위아래(수직)로 단순하게 합치는(연결하는) Pandas 함수는?",
      "options": [
        "pd.concat([df1, df2], axis=0)",
        "pd.merge([df1, df2], axis=0)"
      ],
      "correctAnswer": 0,
      "explanation": "pd.concat()은 여러 DataFrame을 축(axis)을 기준으로 이어붙입니다. axis=0(기본값)은 행(row) 방향(위아래)으로 합칩니다.",
      "code": "combined_df = pd.concat([df1, df2], axis=0)",
      "difficulty": "easy"
    },
    {
      "id": "q266",
      "category": "결측치 처리",
      "question": "(시나리오) 'Age' 컬럼의 결측치를 'Gender' 컬럼별 'Age'의 평균값으로 채우려고 합니다. (예: 남성 결측치는 남성 평균, 여성 결측치는 여성 평균) 올바른 코드는?",
      "options": [
        "df['Age'] = df['Age'].fillna(df.groupby('Gender')['Age'].transform('mean'))",
        "df['Age'] = df['Age'].fillna(df['Age'].mean())"
      ],
      "correctAnswer": 0,
      "explanation": ".groupby().transform('mean')은 각 행이 속한 그룹('Gender')의 평균값을 계산하여 원본 인덱스에 맞게 반환합니다. 이를 fillna()에 적용하면 그룹별 평균 대체가 가능합니다.",
      "code": "df['Age'] = df['Age'].fillna(df.groupby('Gender')['Age'].transform('mean'))",
      "difficulty": "hard"
    },
    {
      "id": "q267",
      "category": "결측치 처리",
      "question": "DataFrame `df`에 결측치가 하나라도 있는지 여부를 (True/False) 확인하는 코드입니다. 빈칸에 알맞은 메서드는?\n\ndf.isnull().____().any()",
      "options": [
        "any",
        "all"
      ],
      "correctAnswer": 0,
      "explanation": "df.isnull()은 셀별로 True/False를 반환합니다. .any()는 컬럼별로 True가 하나라도 있는지 확인하고, .any().any()는 전체 DF에 True가 하나라도 있는지 최종 확인합니다.",
      "code": "print(df.isnull().values.any()) # 더 정확한 방법\nprint(df.isnull().any().any()) # 체이닝 방법",
      "difficulty": "medium"
    },
    {
      "id": "q268",
      "category": "범주형 인코딩",
      "question": "Pandas의 `pd.get_dummies(df, columns=['Color'])`를 실행했을 때, 원본 DataFrame `df`의 'Color' 컬럼은 어떻게 되나요?",
      "options": [
        "자동으로 삭제되고, 원-핫 인코딩된 컬럼들(예: Color_Red)이 추가됩니다.",
        "그대로 남아있고, 원-핫 인코딩된 컬럼들이 추가됩니다."
      ],
      "correctAnswer": 0,
      "explanation": "pd.get_dummies()는 기본적으로 `columns` 파라미터에 지정된 원본 범주형 컬럼을 변환 후 삭제하여 중복을 방지합니다.",
      "code": "df_encoded = pd.get_dummies(df, columns=['Color'])",
      "difficulty": "medium"
    },
    {
      "id": "q269",
      "category": "데이터셋 분리",
      "question": "(시나리오) 1000개의 데이터가 있습니다. 훈련셋 700개, 검증셋 150개, 테스트셋 150개로 분리하는 올바른 전략은?",
      "options": [
        "train_test_split을 두 번 사용합니다. (예: 70% 훈련 / 30% 임시로 나누고, 임시 30%를 다시 50%/50%로 나눔)",
        "train_test_split(train_size=0.7, validation_size=0.15, test_size=0.15)를 한 번에 사용합니다."
      ],
      "correctAnswer": 0,
      "explanation": "train_test_split 함수는 한 번에 훈련/테스트 2개로만 분할할 수 있습니다. 3개로 나누려면 함수를 2번 호출해야 합니다.",
      "code": "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)",
      "difficulty": "medium"
    },
    {
      "id": "q270",
      "category": "스케일링",
      "question": "`StandardScaler`를 사용한 표준화(Standardization)는 데이터를 어떤 분포로 변환하나요?",
      "options": [
        "평균 0, 표준편차 1을 갖도록 변환합니다.",
        "모든 값을 0과 1 사이로 변환합니다."
      ],
      "correctAnswer": 0,
      "explanation": "표준화는 각 값에서 평균을 빼고 표준편차로 나누는 과정 (Z-score)입니다. 이는 데이터의 평균을 0, 표준편차를 1로 만듭니다.",
      "code": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()",
      "difficulty": "easy"
    },
    {
      "id": "q271",
      "category": "스케일링",
      "question": "스케일링, 인코딩, 결측치 처리 등 여러 전처리 단계를 하나로 묶어 파이프라인을 구축할 때 사용하는 scikit-learn 클래스는?",
      "options": [
        "Pipeline",
        "Preprocessor"
      ],
      "correctAnswer": 0,
      "explanation": "Pipeline 클래스는 여러 개의 변환기(Transformer)와 추정기(Estimator)를 연속적으로 실행할 수 있도록 묶어주어, 코드를 간결하게 하고 데이터 누수를 방지합니다.",
      "code": "from sklearn.pipeline import Pipeline\npipe = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression())])",
      "difficulty": "hard"
    },
    {
      "id": "q272",
      "category": "기본 모델링",
      "question": "(시나리오) 'Price' (숫자)를 예측하는 회귀 문제를 풀려고 합니다. 다음 중 사용할 수 없는 scikit-learn 모델은?",
      "options": [
        "LogisticRegression (로지스틱 회귀)",
        "LinearRegression (선형 회귀)"
      ],
      "correctAnswer": 0,
      "explanation": "LogisticRegression (로지스틱 회귀)는 이름과 달리 '분류(Classification)' 알고리즘입니다. LinearRegression (선형 회귀)이 '회귀(Regression)' 문제를 푸는 데 사용됩니다.",
      "code": "from sklearn.linear_model import LinearRegression # 회귀용\n# from sklearn.linear_model import LogisticRegression # 분류용",
      "difficulty": "easy"
    },
    {
      "id": "q273",
      "category": "기본 모델링",
      "question": "모델 학습 후, `model.predict_proba(X_test)` 메서드는 무엇을 반환하나요?",
      "options": [
        "각 클래스에 속할 확률 (예: [0.1, 0.9])",
        "최종 예측된 클래스 (예: 0 또는 1)"
      ],
      "correctAnswer": 0,
      "explanation": ".predict_proba()는 각 샘플이 각 클래스에 속할 확률을 배열로 반환합니다. .predict()는 이 확률 중 가장 높은 쪽의 클래스를 최종적으로 반환합니다.",
      "code": "y_pred_proba = model.predict_proba(X_test)",
      "difficulty": "medium"
    },
    {
      "id": "q274",
      "category": "기본 모델링",
      "question": "모델의 하이퍼파라미터(예: `max_depth`)를 자동으로 튜닝하기 위해, 가능한 모든 조합을 시도하는 scikit-learn 도구는?",
      "options": [
        "GridSearchCV",
        "RandomizedSearchCV"
      ],
      "correctAnswer": 0,
      "explanation": "GridSearchCV는 개발자가 지정한 하이퍼파라미터 그리드(Grid)의 모든 조합을 교차 검증(Cross Validation)을 통해 탐색(Search)합니다.",
      "code": "from sklearn.model_selection import GridSearchCV",
      "difficulty": "medium"
    },
    {
      "id": "q275",
      "category": "기본 모델링",
      "question": "K-Fold 교차 검증(Cross Validation)에서 K=5일 때, 데이터는 어떻게 분할되나요?",
      "options": [
        "데이터를 5개로 나누어, 4개를 훈련에, 1개를 검증에 사용하는 과정을 5번 반복합니다.",
        "데이터를 5개로 나누어, 1개를 훈련에, 4개를 검증에 사용하는 과정을 5번 반복합니다."
      ],
      "correctAnswer": 0,
      "explanation": "K-Fold 교차 검증은 데이터를 K개의 '폴드(fold)'로 나눈 뒤, 각 폴드가 한 번씩 검증셋(validation set)이 되고 나머지가 훈련셋이 되는 과정을 K번 반복합니다.",
      "code": "from sklearn.model_selection import KFold\nkf = KFold(n_splits=5)",
      "difficulty": "medium"
    },
    {
      "id": "q276",
      "category": "앙상블 모델링",
      "question": "`XGBClassifier` 학습 시, 너무 빨리 과적합되는 것을 방지하기 위해 `early_stopping_rounds=20` 파라미터를 설정했습니다. 이 파라미터가 작동하기 위해 반드시 필요한 것은?",
      "options": [
        "model.fit()에 eval_set=[(X_val, y_val)]을 전달해야 합니다.",
        "model.fit()에 n_estimators를 매우 크게 설정해야 합니다."
      ],
      "correctAnswer": 0,
      "explanation": "early_stopping_rounds는 검증셋(eval_set)의 성능이 20 라운드(트리) 동안 개선되지 않으면 학습을 중단시킵니다. 따라서 성능을 모니터링할 검증셋이 반드시 필요합니다.",
      "code": "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=20)",
      "difficulty": "hard"
    },
    {
      "id": "q277",
      "category": "앙상블 모델링",
      "question": "`RandomForestClassifier`에서 `feature_importances_` (특성 중요도)는 어떻게 계산되나요? (주요 기준)",
      "options": [
        "해당 특성(feature)이 트리의 불순도(Impurity)를 얼마나 많이 감소시켰는지",
        "해당 특성의 스케일(값의 크기)이 얼마나 큰지"
      ],
      "correctAnswer": 0,
      "explanation": "트리 모델은 각 노드에서 불순도(Gini 또는 Entropy)를 가장 많이 줄이는 특성을 선택합니다. 특성 중요도는 이 감소량의 총합(또는 평균)을 기준으로 계산됩니다.",
      "code": "importances = model.feature_importances_",
      "difficulty": "hard"
    },
    {
      "id": "q278",
      "category": "앙상블 모델링",
      "question": "모델의 예측 성능은 비슷하지만, `LightGBM`이 `XGBoost`보다 일반적으로 '학습 속도'가 더 빠른 주된 이유는?",
      "options": [
        "리프(Leaf) 중심 트리 분할 및 히스토그램 기반 알고리즘을 사용하기 때문",
        "더 많은 하이퍼파라미터를 제공하기 때문"
      ],
      "correctAnswer": 0,
      "explanation": "LightGBM은 트리를 수평(Level-wise)으로 확장하는 XGBoost와 달리, 손실(loss)이 가장 크게 줄어드는 리프(Leaf-wise)부터 분할하여 더 빠르고 효율적으로 학습합니다.",
      "code": "from lightgbm import LGBMClassifier",
      "difficulty": "hard"
    },
    {
      "id": "q279",
      "category": "모델 성능 평가",
      "question": "(시나리오) 암 진단 모델(1:암, 0:정상)을 만들었습니다. '실제 암 환자(1)를 정상(0)으로 오진'하는 경우(FN)를 최소화하는 것이 가장 중요할 때, 높여야 하는 지표는?",
      "options": [
        "재현율 (Recall)",
        "정밀도 (Precision)"
      ],
      "correctAnswer": 0,
      "explanation": "재현율(Recall = TP / (TP + FN))은 실제 Positive(암) 중에서 모델이 Positive(암)로 맞춘 비율입니다. FN(오진)을 낮추는 것이 목표이므로 재현율을 높여야 합니다.",
      "code": "from sklearn.metrics import recall_score",
      "difficulty": "hard"
    },
    {
      "id": "q280",
      "category": "모델 성능 평가",
      "question": "(시나리오) 스팸 메일 분류기(1:스팸, 0:정상)를 만들었습니다. '실제 정상 메일(0)을 스팸(1)으로 오진'하는 경우(FP)를 최소화하는 것이 가장 중요할 때, 높여야 하는 지표는?",
      "options": [
        "정밀도 (Precision)",
        "재현율 (Recall)"
      ],
      "correctAnswer": 0,
      "explanation": "정밀도(Precision = TP / (TP + FP))는 모델이 Positive(스팸)로 예측한 것 중 실제 Positive(스팸)인 비율입니다. FP(오진)를 낮추는 것이 목표이므로 정밀도를 높여야 합니다.",
      "code": "from sklearn.metrics import precision_score",
      "difficulty": "hard"
    },
    {
      "id": "q281",
      "category": "모델 성능 평가",
      "question": "정밀도(Precision)와 재현율(Recall)이 모두 중요한 상황일 때, 두 지표의 조화평균을 나타내는 성능 지표는?",
      "options": [
        "F1 Score",
        "Accuracy (정확도)"
      ],
      "correctAnswer": 0,
      "explanation": "F1 Score는 정밀도와 재현율의 조화평균 (2 * (Precision * Recall) / (Precision + Recall))으로, 두 지표가 한쪽으로 치우치지 않고 균형을 이룰 때 높아집니다.",
      "code": "from sklearn.metrics import f1_score",
      "difficulty": "medium"
    },
    {
      "id": "q282",
      "category": "모델 성능 평가",
      "question": "회귀 모델의 성능을 평가할 때, '예측값(y_pred)'과 '실제값(y_test)'의 순서가 바뀌어도 결과가 동일한 지표는?",
      "options": [
        "MSE (Mean Squared Error)",
        "R² Score (결정 계수)"
      ],
      "correctAnswer": 0,
      "explanation": "MSE나 MAE는 (예측값 - 실제값)의 차이를 기반으로 하므로 순서가 바뀌어도 (실제값 - 예측값)의 제곱/절대값은 동일합니다. 하지만 R² Score는 순서가 바뀌면 결과가 달라집니다.",
      "code": "mean_squared_error(y_test, y_pred) == mean_squared_error(y_pred, y_test) # True",
      "difficulty": "medium"
    },
    {
      "id": "q283",
      "category": "딥러닝 모델 구성",
      "question": "Keras Sequential 모델의 첫 번째 레이어(예: Dense)에 `input_shape=(10,)` 파라미터를 지정하는 이유는 무엇인가요?",
      "options": [
        "모델이 입력 데이터의 형태(feature 개수)를 알 수 있도록 하기 위해",
        "모델이 출력 데이터의 형태(class 개수)를 알 수 있도록 하기 위해"
      ],
      "correctAnswer": 0,
      "explanation": "모델의 첫 번째 레이어는 입력 데이터가 몇 개의 특성(feature)으로 구성되어 있는지 알아야 가중치(W) 행렬을 생성할 수 있습니다. `input_shape`는 이 입력 형태를 지정합니다.",
      "code": "model.add(keras.layers.Dense(64, activation='relu', input_shape=(10,)))",
      "difficulty": "easy"
    },
    {
      "id": "q284",
      "category": "딥러닝 모델 구성",
      "question": "Keras 모델의 Dense 레이어에서 `activation='relu'` (ReLU 함수)를 사용하는 주된 이유는 무엇인가요?",
      "options": [
        "학습 과정에서 기울기 소실(Vanishing Gradient) 문제를 완화하고 학습 속도를 높이기 위해",
        "최종 예측 확률을 0과 1 사이로 만들기 위해"
      ],
      "correctAnswer": 0,
      "explanation": "ReLU(Rectified Linear Unit)는 입력이 0보다 크면 값을 그대로, 0보다 작으면 0을 출력합니다. 이는 Sigmoid나 Tanh와 달리 기울기 소실 문제가 적어 딥러닝 은닉층(hidden layer)에서 널리 사용됩니다.",
      "code": "model.add(keras.layers.Dense(64, activation='relu'))",
      "difficulty": "medium"
    },
    {
      "id": "q285",
      "category": "딥러닝 모델 구성",
      "question": "(시나리오) 딥러닝 모델의 훈련 손실(loss)은 계속 낮아지는데, 검증 손실(val_loss)은 어느 시점부터 다시 높아지고 있습니다. 이 현상을 무엇이라고 하나요?",
      "options": [
        "과적합 (Overfitting)",
        "과소적합 (Underfitting)"
      ],
      "correctAnswer": 0,
      "explanation": "과적합은 모델이 훈련 데이터에만 너무 치중하여, 새로운 데이터(검증셋)에 대한 일반화 성능이 떨어지는 현상을 의미합니다.",
      "code": "# 훈련 손실은 감소, 검증 손실은 증가 -> 과적합 발생\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])",
      "difficulty": "easy"
    },
    {
      "id": "q286",
      "category": "딥러닝 모델 구성",
      "question": "딥러닝 모델의 과적합(Overfitting)을 방지하기 위해, 학습 시 뉴런의 일부를 랜덤하게 비활성화하는 레이어는?",
      "options": [
        "keras.layers.Dropout(0.3)",
        "keras.layers.Reduce(0.3)"
      ],
      "correctAnswer": 0,
      "explanation": "드롭아웃(Dropout)은 훈련 과정에서 지정된 비율(예: 30%)만큼의 뉴런을 랜덤하게 'OFF'시켜, 모델이 특정 뉴런에 과도하게 의존하는 것을 방지하는 규제(Regularization) 기법입니다.",
      "code": "model.add(keras.layers.Dropout(0.3))",
      "difficulty": "easy"
    },
    {
      "id": "q287",
      "category": "딥러닝 모델 구성",
      "question": "`model.compile()`에서 `optimizer='adam'`을 설정했습니다. 'Adam' 옵티마이저의 주된 역할은 무엇인가요?",
      "options": [
        "모델의 가중치(Weight)를 효율적으로 업데이트하여 손실 함수(loss)를 최소화합니다.",
        "모델의 예측 정확도(accuracy)를 직접 계산합니다."
      ],
      "correctAnswer": 0,
      "explanation": "옵티마이저(Optimizer)는 경사 하강법(Gradient Descent)을 기반으로, 손실 함수의 기울기(gradient)를 계산하여 모델의 가중치를 더 나은 방향으로 업데이트하는 역할을 합니다.",
      "code": "model.compile(optimizer='adam', loss='binary_crossentropy')",
      "difficulty": "medium"
    },
    {
      "id": "q288",
      "category": "딥러닝 모델 구성",
      "question": "Keras 모델의 `model.fit()`에서 `epochs=100`과 `batch_size=32`는 무엇을 의미하나요?",
      "options": [
        "전체 훈련 데이터를 32개씩 나누어 학습하고, 이 과정을 총 100번 반복합니다.",
        "전체 훈련 데이터를 100개씩 나누어 학습하고, 이 과정을 총 32번 반복합니다."
      ],
      "correctAnswer": 0,
      "explanation": "batch_size는 한 번의 가중치 업데이트에 사용할 데이터 샘플의 개수이며, epoch는 전체 훈련 데이터셋을 몇 번 반복하여 학습할지를 의미합니다.",
      "code": "model.fit(X_train, y_train, epochs=100, batch_size=32)",
      "difficulty": "medium"
    },
    {
      "id": "q289",
      "category": "딥러닝 평가 및 시각화",
      "question": "`model.fit()`을 실행할 때 `validation_data=(X_val, y_val)`을 전달하는 주된 이유는?",
      "options": [
        "매 에포크(epoch)마다 모델이 과적합되고 있는지 검증(validation)하기 위해",
        "테스트(test) 데이터로 최종 성능을 평가하기 위해"
      ],
      "correctAnswer": 0,
      "explanation": "validation_data를 전달하면, 모델은 훈련(train)에 사용되지 않은 이 검증 데이터로 성능을 평가합니다. 이 검증 손실(val_loss)을 모니터링하여 과적합이나 EarlyStopping을 판단합니다.",
      "code": "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))",
      "difficulty": "medium"
    },
    {
      "id": "q290",
      "category": "딥러닝 평가 및 시각화",
      "question": "학습이 완료된 Keras 모델의 최종 성능을 '테스트 데이터(X_test, y_test)'로 평가하는 메서드는?",
      "options": [
        "model.evaluate(X_test, y_test)",
        "model.predict(X_test, y_test)"
      ],
      "correctAnswer": 0,
      "explanation": "model.evaluate()는 테스트 데이터를 사용하여 compile 시 설정한 손실(loss)과 지표(metrics)를 계산하여 반환합니다. model.predict()는 예측값만 반환합니다.",
      "code": "test_loss, test_acc = model.evaluate(X_test, y_test)",
      "difficulty": "easy"
    },
    {
      "id": "q291",
      "category": "라이브러리 임포트",
      "question": "Pandas DataFrame을 생성하는 코드입니다. 빈칸에 알맞은 클래스명은?\n\ndata = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.____(data)",
      "options": [
        "DataFrame",
        "Series"
      ],
      "correctAnswer": 0,
      "explanation": "pd.DataFrame()은 딕셔너리나 리스트 등을 기반으로 2차원 테이블 형태의 DataFrame 객체를 생성합니다. pd.Series()는 1차원 배열(단일 컬럼)을 생성합니다.",
      "code": "import pandas as pd\ndata = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data)",
      "difficulty": "easy"
    },
    {
      "id": "q292",
      "category": "데이터 전처리",
      "question": "DataFrame `df`의 행(row)과 열(column)을 서로 뒤바꾸는(Transpose) 속성은?",
      "options": [
        "df.T",
        "df.transpose()"
      ],
      "correctAnswer": 0,
      "explanation": ".T 속성(Attribute)은 DataFrame의 행과 열을 전치(Transpose)시킵니다. .transpose() 메서드도 동일한 기능을 수행합니다.",
      "code": "df_transposed = df.T",
      "difficulty": "medium"
    },
    {
      "id": "q293",
      "category": "데이터 전처리",
      "question": "DataFrame `df`에서 'col1'이 10보다 크고 'col2'가 'A'인 행만 필터링하는 올바른 코드는?",
      "options": [
        "df[(df['col1'] > 10) & (df['col2'] == 'A')]",
        "df[df['col1'] > 10 and df['col2'] == 'A']"
      ],
      "correctAnswer": 0,
      "explanation": "Pandas에서 여러 조건을 동시에 만족(AND)시키려면 `&` 연산자를 사용해야 하며, 각 조건은 소괄호 `()`로 묶어주어야 합니다. (OR 조건은 `|` 사용)",
      "code": "filtered_df = df[(df['col1'] > 10) & (df['col2'] == 'A')]",
      "difficulty": "medium"
    },
    {
      "id": "q294",
      "category": "데이터 전처리",
      "question": "DataFrame `df`에서 'Category' 컬럼의 값이 'A' 또는 'B'인 행만 필터링하는 효율적인 코드는?",
      "options": [
        "df[df['Category'].isin(['A', 'B'])]",
        "df[(df['Category'] == 'A') | (df['Category'] == 'B')]"
      ],
      "correctAnswer": 0,
      "explanation": ".isin() 메서드는 리스트에 포함된 값들 중 하나라도 일치하는 행을 찾아줍니다. OR(|) 연산자를 여러 번 쓰는 것보다 간결하고 효율적입니다.",
      "code": "filtered_df = df[df['Category'].isin(['A', 'B'])]",
      "difficulty": "medium"
    },
    {
      "id": "q295",
      "category": "데이터 전처리",
      "question": "DataFrame `df`에서 'Sales' 컬럼을 기준으로 내림차순(큰 값이 위로) 정렬하는 코드는?",
      "options": [
        "df.sort_values('Sales', ascending=False)",
        "df.sort_values('Sales', ascending=True)"
      ],
      "correctAnswer": 0,
      "explanation": "sort_values() 메서드는 특정 컬럼을 기준으로 데이터를 정렬합니다. ascending=False는 내림차순(Descending)을, ascending=True(기본값)는 오름차순(Ascending)을 의미합니다.",
      "code": "df_sorted = df.sort_values('Sales', ascending=False)",
      "difficulty": "easy"
    },
    {
      "id": "q296",
      "category": "데이터 전처리",
      "question": "DataFrame `df`에서 중복된 행(row)을 제거하는 메서드는?",
      "options": [
        "df.drop_duplicates()",
        "df.remove_duplicates()"
      ],
      "correctAnswer": 0,
      "explanation": "drop_duplicates() 메서드는 모든 컬럼의 값이 완전히 동일한 중복 행을 찾아 제거합니다.",
      "code": "df_unique = df.drop_duplicates()",
      "difficulty": "easy"
    },
    {
      "id": "q297",
      "category": "데이터 전처리",
      "question": "DataFrame `df`의 'col1' 컬럼에 1, 2, 3이 있을 때, `df['col1'].apply(lambda x: x * 2)`를 실행하면 어떤 결과가 나오나요?",
      "options": [
        "각 원소에 2가 곱해진 Series (2, 4, 6)가 반환됩니다.",
        "에러가 발생합니다."
      ],
      "correctAnswer": 0,
      "explanation": "apply() 메서드는 Series의 각 원소(x)에 대해 lambda 함수를 순차적으로 적용(apply)하여 새로운 Series를 반환합니다.",
      "code": "df['col1_doubled'] = df['col1'].apply(lambda x: x * 2)",
      "difficulty": "medium"
    },
    {
      "id": "q298",
      "category": "데이터 불러오기",
      "question": "매우 큰 CSV 파일('large_data.csv')을 메모리 문제 없이 처리하기 위해 10000줄씩 나누어 읽는 파라미터는?",
      "options": [
        "chunksize=10000",
        "batch_size=10000"
      ],
      "correctAnswer": 0,
      "explanation": "chunksize 파라미터를 설정하면 pd.read_csv()는 전체를 읽는 대신, 지정된 줄(chunk) 단위로 데이터를 읽는 'Iterator'를 반환합니다. 이는 for문과 함께 사용됩니다.",
      "code": "for chunk in pd.read_csv('large_data.csv', chunksize=10000):\n    # chunk (10000줄) 단위로 처리\n    process(chunk)",
      "difficulty": "hard"
    },
    {
      "id": "q299",
      "category": "앙상블 모델링",
      "question": "모델의 특성 중요도(feature importances)를 시각화하기에 가장 적합한 그래프 유형은?",
      "options": [
        "sns.barplot (막대 그래프)",
        "sns.scatterplot (산점도)"
      ],
      "correctAnswer": 0,
      "explanation": "막대 그래프(Bar plot)는 각 특성(feature)의 이름(범주형)에 따른 중요도 값(수치형)을 시각적으로 비교하기에 가장 적합합니다.",
      "code": "importances = model.feature_importances_\nfeatures = X_train.columns\nsns.barplot(x=importances, y=features)",
      "difficulty": "easy"
    },
    {
      "id": "q300",
      "category": "모델 성능 평가",
      "question": "회귀 모델의 성능 지표인 R²(R-squared, 결정계수) 값이 1.0에 가깝다는 것은 무엇을 의미하나요?",
      "options": [
        "모델이 데이터의 분산을 거의 완벽하게 설명하고 있다는 의미입니다.",
        "모델이 데이터의 분산을 전혀 설명하지 못하고 있다는 의미입니다."
      ],
      "correctAnswer": 0,
      "explanation": "R²는 모델이 타겟 변수(y)의 분산을 얼마나 잘 설명하는지를 0과 1 사이의 값으로 나타냅니다. 1에 가까울수록 모델이 데이터를 잘 적합(fit)시켰음을 의미합니다.",
      "code": "from sklearn.metrics import r2_score\nr2 = r2_score(y_test, y_pred)",
      "difficulty": "medium"
    }
]